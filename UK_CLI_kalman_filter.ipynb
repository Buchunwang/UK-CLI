{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNGgyjy2evockDX8krE5sRk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Buchunwang/UK-CLI/blob/main/UK_CLI_kalman_filter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we import detrended data of CLI and its component variables from 1986 to 2021"
      ],
      "metadata": {
        "id": "oJZQg-yexsXE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHXNcvn2L1-R",
        "outputId": "65e719d4-3307-42e6-b49e-77c3a194b167"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From URL: https://raw.githubusercontent.com/Buchunwang/UK-CLI/main/kalpre.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "url = 'https://raw.githubusercontent.com/Buchunwang/UK-CLI/main/kalpre.csv'\n",
        "print('From URL:', url)\n",
        "kalpre = pd.read_csv(url, header=None, encoding='utf-8', skiprows=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we standardize the data"
      ],
      "metadata": {
        "id": "MtZOQbHtv5KK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scale= StandardScaler()\n",
        "kalpre = scale.fit_transform(kalpre) \n",
        "print(kalpre)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2QzS9VqyC91",
        "outputId": "ce1877bc-d58a-4672-9a7b-07a38f754f5e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4.77728394e-02 -1.06056869e-02  3.00724295e-03 ... -1.03166195e-01\n",
            "   8.00207365e-03 -6.11869099e-02]\n",
            " [ 9.88213626e-02  5.18563334e-02 -7.53982191e-03 ...  3.85044329e-01\n",
            "   1.64688170e+00  1.85709938e+00]\n",
            " [ 7.23062404e-02  1.03068101e-01  5.50476655e-02 ...  3.08487391e+00\n",
            "  -1.26525437e+00  1.62538219e+00]\n",
            " ...\n",
            " [-2.48640418e-01  1.30844793e+00 -2.29908393e-01 ... -6.93214447e-02\n",
            "  -2.77564022e+00  3.46200192e+00]\n",
            " [ 1.28896015e+00 -2.45504802e-01  1.31416337e+00 ... -6.93214447e-02\n",
            "   4.81092770e-01  8.82828354e-01]\n",
            " [ 1.63507006e+00  1.29701274e+00 -2.42910777e-01 ... -1.03166195e-01\n",
            "  -2.63429707e+00 -5.11759895e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "N = 421\n",
        "Y = np.transpose(kalpre[:,3:9])\n",
        "lamda = np.zeros((1, 5))\n",
        "D = np.zeros((1, 5))\n",
        "var_e = np.zeros((1, 5))\n",
        "var_ep = np.zeros((1, 5))\n",
        "xe = np.zeros((N - 2, 2))\n",
        "psi = np.zeros((5, 2))\n",
        "\n",
        "for i in range(5):\n",
        "    reg = LinearRegression(fit_intercept=True)\n",
        "    reg.fit(kalpre[:, 0:1], Y[i, :])\n",
        "    lamda[0, i] = reg.coef_[0]\n",
        "    D[0, i] = reg.intercept_\n",
        "    r = Y[i, :] - reg.predict(kalpre[:, 0:1])\n",
        "    var_e[0, i] = np.var(r)\n",
        "    \n",
        "    xe[:, 0] = r[1:N-1]\n",
        "    xe[:, 1] = r[0:N-2]\n",
        "    reg2 = LinearRegression(fit_intercept=False)\n",
        "    reg2.fit(xe, r[2:N])\n",
        "    var_ep[0, i] = np.var(reg2.predict(xe) - r[2:N])\n",
        "    psi[i, 0] = reg2.coef_[0]\n",
        "    psi[i, 1] = reg2.coef_[1]\n"
      ],
      "metadata": {
        "id": "ahpJhG2wYQPW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import statsmodels.api as sm\n",
        "# Calculate delta_y, delta_y_t-1, and delta_y_t-2\n",
        "y = np.zeros((5, N))\n",
        "y1lag = np.zeros((5, N))\n",
        "y2lag = np.zeros((5, N))\n",
        "for i in range(5):\n",
        "    y[i-1, :] = kalpre[:, i + 2] - np.mean(kalpre[:, i + 2])\n",
        "    y1lag[i-1, :] = kalpre[:, i + 7] - np.mean(kalpre[:, i + 7])\n",
        "    y2lag[i-1, :] = kalpre[:, i + 12] - np.mean(kalpre[:, i + 12])\n",
        "\n",
        "# Calculate phi\n",
        "# Calculate phi based on equation 3 of Kim and Nelson\n",
        "regressor = kalpre[:, 1:3] - np.mean(kalpre[:, 1:3], axis=0)  # 2nd and 3rd columns of kalpre\n",
        "response = kalpre[:, 0] - np.mean(kalpre[:, 0])  # 1st column of kalpre\n",
        "regressor = sm.add_constant(regressor)\n",
        "model = sm.OLS(response, regressor)\n",
        "result = model.fit()\n",
        "phi = result.params\n",
        "var_vt = np.var(result.resid)\n",
        "mu_st = kalpre[:, 0] - phi[0] * kalpre[:, 1] - phi[1] * kalpre[:, 2] - np.mean(kalpre[:, 0]) - \\\n",
        "        norm.rvs(loc=0, scale=np.sqrt(var_vt), size=N,)\n",
        "mu_st = mu_st.reshape((1, -1))\n",
        "\n",
        "\n",
        "# Construct H and A\n",
        "H = np.array([[lamda[0,0], -lamda[0,0]*psi[0, 0], -lamda[0,0]*psi[0, 1]],\n",
        "              [lamda[0,1], -lamda[0,1]*psi[1, 0], -lamda[0,1]*psi[1, 1]],\n",
        "              [lamda[0,2], -lamda[0,2]*psi[2, 0], -lamda[0,2]*psi[2, 1]],\n",
        "              [lamda[0,3], -lamda[0,3]*psi[3, 0], -lamda[0,3]*psi[3, 1]],\n",
        "              [lamda[0,4], -lamda[0,4]*psi[4, 0], -lamda[0,4]*psi[4, 1]]])\n",
        "A = np.array([[phi[0], phi[1], 0],\n",
        "              [0, phi[0], phi[1]],\n",
        "              [0, 1, 0]])\n",
        "\n",
        "# Construct delta_y*\n",
        "ystar = y.T - np.multiply(psi[:, 0].T, y1lag[0:5, :].T)- np.multiply(psi[:, 1].T,y2lag[0:5, :].T)\n",
        "ystar=ystar.T\n",
        "\n",
        "\n",
        "# Initialize variables\n",
        "Q = np.array([[var_vt, 0, 0],\n",
        "[0, var_vt, 0],\n",
        "[0, 0, 0]])\n",
        "R = np.array([[var_ep[0,0], 0, 0, 0, 0],\n",
        "             [0, var_ep[0,1], 0, 0, 0],\n",
        "             [0, 0, var_ep[0,2], 0, 0],\n",
        "             [0, 0, 0, var_ep[0,3], 0],\n",
        "             [0, 0, 0, 0, var_ep[0,4]]])\n",
        "P = 0.1 * np.eye(3)\n",
        "z = np.ones((5, N))\n",
        "k = 0\n",
        "true5D = ystar\n",
        "x = np.zeros((3, N))\n",
        "vct = np.zeros((3, N))\n"
      ],
      "metadata": {
        "id": "L5aA430jJ3gR"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 0\n",
        "for t in range(N-1):\n",
        "    k += 1\n",
        "    x[:, k] = np.dot(A, x[:, k-1])  # + mut[:, k]  # Kalman equation 1\n",
        "    P = np.dot(A, np.dot(P, A.T)) + Q  # Kalman equation 2\n",
        "    K = np.dot(P, np.dot(H.T, np.linalg.inv(np.dot(H, np.dot(P, H.T)) + R)))  # Kalman equation 3\n",
        "    z[:, k] = [true5D[0, k], true5D[1, k], true5D[2, k], true5D[3, k], true5D[4, k]]   \n",
        "    x[:, k] = x[:, k] + np.dot(K, (z[:, k] - np.dot(H, x[:, k])))  # Kalman equation 4\n",
        "    P = np.dot((np.eye(3) - np.dot(K, H)), P)  # Kalman equation 5\n",
        "    vct[0, k] = P[0, 0]  # save variance of delta_ct\n",
        "    vct[1, k] = P[1, 1]\n",
        "    vct[2, k] = P[2, 2]"
      ],
      "metadata": {
        "id": "vtCW_HX4da1F"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "step2"
      ],
      "metadata": {
        "id": "e43BLmF9cznS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random import normal\n",
        "\n",
        "c = normal(x[0, N-1], np.sqrt(vct[0, N-1]))  # generate delta_c_T\n",
        "xi = np.zeros((1, N))\n",
        "V = np.zeros((1, N))\n",
        "for i in range(N-1):  # this loop is just for xi_t and V_t conditional on delta_ct+1 for t=1,2,...,T-1\n",
        "    eta = c - mu_st[0,N-i-1] - phi[0]*x[0, N-i-2] - phi[1]*x[1, N-i-2]  # value of eta_t two lag in my model, that's why I have term -phi(2)*x(2,N-i)\n",
        "    Rt = np.sum(A[0]*vct[:, N-i-1]*A[0])+var_vt\n",
        "    xi[0, N-i-1] = x[0, N-i-2] + phi[0]*vct[0, N-i-1]*eta/Rt\n",
        "    # we only use first row of the mean and variance vector\n",
        "    # so I calculated the first element of each mean & variance directly\n",
        "    V[0, N-i-1] = vct[0, N-i-1] - phi[0]**2 * vct[0,N-i-1]**2 / Rt\n",
        "    c = normal(xi[0, N-i-1], np.sqrt(V[0, N-i-1]))\n",
        "V[0, N-1] = vct[0, N-1]\n",
        "xi[0, N-1] = x[0, N-1]\n",
        "delta=0.0022\n",
        "delta_C=np.zeros((N,1))\n",
        "C0=99.72203"
      ],
      "metadata": {
        "id": "BZMQ-D3y2vxc"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy.random import normal\n",
        "\n",
        "newCLI = np.zeros((N, 1))\n",
        "p = 1000\n",
        "mc = np.zeros((p, 1))\n",
        "for m in range(p):\n",
        "    mc[m] = C0 + normal(xi[0,0], np.sqrt(V[0,0])) + delta\n",
        "newCLI[0] = np.mean(mc)\n",
        "mc = np.zeros((p, 1))\n",
        "for i in range(1, N):\n",
        "    for m in range(p):\n",
        "        mc[m] = newCLI[i-1] + normal(xi[0,i], np.sqrt(V[0,i]))\n",
        "    newCLI[i] = np.mean(mc) # new delta_C_t=delta_c_t+C_{t-1}+delta according to appendix A7\n",
        "\n",
        "cc = np.zeros((N, 1))\n",
        "mc = np.zeros((p, 1))\n",
        "for m in range(p):\n",
        "    mc[m] = delta + C0 + normal(x[0, 0], np.sqrt(vct[0, 0]))\n",
        "cc[0] = np.mean(mc)\n",
        "for i in range(1, N):\n",
        "    for m in range(p):\n",
        "        mc[m] = cc[i-1] + normal(x[0, i], np.sqrt(vct[0, i]))\n",
        "    cc[i] = np.mean(mc)"
      ],
      "metadata": {
        "id": "-Y0iAjxc8tEp"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have finished the Kalman filter part, then we come to the Hamilton Basic filter"
      ],
      "metadata": {
        "id": "9Yyjf1VLZpnn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kmNuSP5zZ2dZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}