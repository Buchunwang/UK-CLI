{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP25ZTRnczrh4hKK2dzBG/b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Buchunwang/UK-CLI/blob/main/kim_nelson_uk_data_22_07_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aE2WbK2XnZ63",
        "outputId": "60084696-a152-42b8-e735-8bbb15c58b3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From URL: https://raw.githubusercontent.com/Buchunwang/UK-CLI/main/Kalman%20filter/kalpre.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "url = 'https://raw.githubusercontent.com/Buchunwang/UK-CLI/main/Kalman%20filter/kalpre.csv'\n",
        "print('From URL:', url)\n",
        "kalpre = pd.read_csv(url, header=None, encoding='utf-8', skiprows=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#final code\n",
        "\n",
        "##########################################################################\n",
        "#          pre-setting\n",
        "##########################################################################\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import statsmodels.api as sm\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.stats import invgamma\n",
        "scale= StandardScaler()\n",
        "kalpre = scale.fit_transform(kalpre)#standardize data\n",
        "np.random.seed(123) #fix randomness\n",
        "N = 421 #length of input\n",
        "Y = np.transpose(kalpre[:,3:9])#Y_{1t} to Y_{5t}\n",
        "# Calculate delta_y, delta_y_t-1, and delta_y_t-2\n",
        "# Yit-E(Y), remove the mean value\n",
        "y = np.zeros((5, N))\n",
        "y1lag = np.zeros((5, N))\n",
        "y2lag = np.zeros((5, N))\n",
        "for i in range(5):\n",
        "    y[i-1, :] = kalpre[:, i + 2] - np.mean(kalpre[:, i + 2])\n",
        "    y1lag[i-1, :] = kalpre[:, i + 7] - np.mean(kalpre[:, i + 7])\n",
        "    y2lag[i-1, :] = kalpre[:, i + 12] - np.mean(kalpre[:, i + 12])\n",
        "x = np.zeros((3, N))#empty matrix to save mean value of xi_t\n",
        "\n",
        "var_vt=1\n",
        "#Q_kal = np.array([[1, 0, 0],\n",
        "#[0, 1, 0],\n",
        "#[0, 0, 0]])\n",
        "\n",
        "Q_kal = np.array([[var_vt, 0, 0],\n",
        "[0, var_vt, 0],\n",
        "[0, 0, 0]])\n",
        "#Q in kalman filter, process noise, we rename it as Q_kal\n",
        "# to avoid repeated use of Q in Gibbs sampling\n",
        "phi=np.zeros(2)\n",
        "psi=np.zeros((5,2))\n",
        "\n",
        "x = np.zeros((3, N))#empty matrix to save mean value of xi_t\n",
        "vct = np.zeros((3, N))#empty matrix to save variance of xi_t\n",
        "\n",
        "\n",
        "\n",
        "mu_st=np.zeros(N) #this is for kalman filter\n",
        "\n",
        "######################################################\n",
        "# The following settings are for estimation of parameters in after hmailton basic filter\n",
        "iter = 10000 # number of iterations\n",
        "burn = 2000 #we burn the first 2000 iterations and sampling from the later 8000 iterations in the Monter Carlo\n",
        "#Now we begin to set the initial values of parameters wwe are going to estimate in the algorithm\n",
        "\n",
        "# As this code is a mixture of three independent code, unavoidabely there are repeated variables\n",
        "#such as N, to avoid troubles (as N used in too many places), we will modify the value of N in the loop\n",
        "N=419\n",
        "\n",
        "phi_1 = np.random.normal(0, 1, (N - 4, 1))\n",
        "phi_2 = np.random.normal(0, 1, (N - 4, 1))\n",
        "lamda_1 = np.random.normal(0, 1, (N, 1))\n",
        "#these are just initial settings,\n",
        "#later on we will draw samples of thses parameters by newly generated mean and variance (or other distribution parameters for other types of distribution)\n",
        "lamda_2 = np.random.normal(0, 1, (N, 1))\n",
        "lamda_3 = np.random.normal(0, 1, (N, 1))\n",
        "lamda_4 = np.random.normal(0, 1, (N, 1))\n",
        "lamda_5 = np.random.normal(0, 1, (N, 1))\n",
        "Psi1 = np.random.normal(0, 1, (N - 2, 2))\n",
        "Psi2 = np.random.normal(0, 1, (N - 2, 2))\n",
        "Psi3 = np.random.normal(0, 1, (N - 2, 2))\n",
        "Psi4 = np.random.normal(0, 1, (N - 2, 2))\n",
        "Psi5 = np.random.normal(0, 1, (N - 2, 2))\n",
        "rrighta3 = np.zeros((1, N - 2))#this matrix is for calculating distribution of lamda\n",
        "q = np.random.binomial(0.9, 0.066)\n",
        "p = np.random.binomial(0.967, 0.032)\n",
        "sig1 = 0.2 #initial value of sigma_i\n",
        "sig2 = 0.2\n",
        "sig3 = 0.2\n",
        "sig4 = 0.2\n",
        "sig5 = 0.2\n",
        "\n",
        "St=np.zeros(N)\n",
        "mu0 = 0\n",
        "mu1 = 0\n",
        "mut = np.zeros(N-2)#corresponding regime for t=3 to N, this is for estimating parameters\n",
        "\n",
        "\n",
        "# variance and mean initial set\n",
        "varlamda1 = 1\n",
        "varlamda2 = 1\n",
        "varlamda3 = 1\n",
        "varlamda4 = 1\n",
        "varlamda5 = 1\n",
        "meanlamda1 = 0 #lamda_1~N(meanlamda1,varlamda1)\n",
        "meanlamda2 = 0\n",
        "meanlamda3 = 0\n",
        "meanlamda4 = 0\n",
        "meanlamda5 = 0\n",
        "varpsi1 = np.eye(2)\n",
        "varpsi2 = np.eye(2)\n",
        "varpsi3 = np.eye(2)\n",
        "varpsi4 = np.eye(2)\n",
        "varpsi5 = np.eye(2)\n",
        "meanpsi1 = np.zeros((2, 1))#psi_1~N(meanpsi1,varpsi1), meanpsi1=np.array([[a],[b]]),varpsii1=np.array([[a1,a2],[b1,b2]])\n",
        "meanpsi2 = np.zeros((2, 1))\n",
        "meanpsi3 = np.zeros((2, 1))\n",
        "meanpsi4 = np.zeros((2, 1))\n",
        "meanpsi5 = np.zeros((2, 1))\n",
        "sig1a = 4 + N / 2 #sigma_1~IG(sig1a,sig1b) inverse gamma distribution\n",
        "sig2a = 4 + N / 2\n",
        "sig3a = 4 + N / 2\n",
        "sig4a = 4 + N / 2\n",
        "sig5a = 4 + N / 2\n",
        "sig1b = 4\n",
        "sig2b = 4\n",
        "sig3b = 4\n",
        "sig4b = 4\n",
        "sig5b = 4\n",
        "X1 = np.zeros((N - 2, 2))\n",
        "X2 = np.zeros((N - 2, 2))\n",
        "X3 = np.zeros((N - 2, 2))\n",
        "X4 = np.zeros((N - 2, 2))\n",
        "X5 = np.zeros((N - 2, 2))\n",
        "varphi = np.array([[1, 0], [0,1]])\n",
        "meanphi = np.array([[0], [0]])\n",
        "varmu = np.array([[1, 0], [0, 1]])\n",
        "meanmu = np.array([[0], [0]])\n",
        "Q = np.zeros((N - 4, 2))\n",
        "Qstar = np.zeros((N - 4, 2))\n",
        "fvarphi = np.array([[1, 0], [0, 1]])\n",
        "# Output\n",
        "# We set some empty matrices here to save values from each iteration\n",
        "# After the 2000 burn-in period, we need to save value for later 80000 iterations\n",
        "mlamda1 = np.zeros(8000)\n",
        "mlamda2 = np.zeros(8000)\n",
        "mlamda3 = np.zeros(8000)\n",
        "mlamda4 = np.zeros(8000)\n",
        "mlamda5 = np.zeros(8000)\n",
        "vlamda1 = np.zeros(8000)\n",
        "vlamda2 = np.zeros(8000)\n",
        "vlamda3 = np.zeros(8000)\n",
        "vlamda4 = np.zeros(8000)\n",
        "vlamda5 = np.zeros(8000)\n",
        "bsig1 = np.zeros(8000)\n",
        "bsig2 = np.zeros(8000)\n",
        "bsig3 = np.zeros(8000)\n",
        "bsig4 = np.zeros(8000)\n",
        "bsig5 = np.zeros(8000)\n",
        "mpsi11 = np.zeros(8000)\n",
        "mpsi21 = np.zeros(8000)\n",
        "mpsi31 = np.zeros(8000)\n",
        "mpsi41 = np.zeros(8000)\n",
        "mpsi12 = np.zeros(8000)\n",
        "mpsi22 = np.zeros(8000)\n",
        "mpsi32 = np.zeros(8000)\n",
        "mpsi42 = np.zeros(8000)\n",
        "mpsi51 = np.zeros(8000)\n",
        "mpsi52 = np.zeros(8000)\n",
        "vpsi11 = np.zeros(8000)\n",
        "vpsi21 = np.zeros(8000)\n",
        "vpsi31 = np.zeros(8000)\n",
        "vpsi41 = np.zeros(8000)\n",
        "vpsi12 = np.zeros(8000)\n",
        "vpsi22 = np.zeros(8000)\n",
        "vpsi32 = np.zeros(8000)\n",
        "vpsi42 = np.zeros(8000)\n",
        "vpsi51 = np.zeros(8000)\n",
        "vpsi52 = np.zeros(8000)\n",
        "mphi1 = np.zeros(8000)\n",
        "mphi2 = np.zeros(8000)\n",
        "vphi1 = np.zeros(8000)\n",
        "vphi2 = np.zeros(8000)\n",
        "mmu1 = np.zeros(8000)\n",
        "mmu2 = np.zeros(8000)\n",
        "vmu1 = np.zeros(8000)\n",
        "vmu2 = np.zeros(8000)\n",
        "sig1 = np.sqrt(1 / np.random.gamma(sig1a, 1 / sig1b))\n",
        "sig2 = np.sqrt(1 / np.random.gamma(sig2a, 1 / sig2b))\n",
        "sig3 = np.sqrt(1 / np.random.gamma(sig3a, 1 / sig3b))\n",
        "sig4 = np.sqrt(1 / np.random.gamma(sig4a, 1 / sig4b))\n",
        "sig5 = np.sqrt(1 / np.random.gamma(sig5a, 1 / sig5b))\n",
        "transition_prob_p=np.zeros(8000)\n",
        "transition_prob_q=np.zeros(8000)\n",
        "delta=np.zeros(8000)\n",
        "# Initialize the DataFrame with the size of 8x419 with NaNs\n",
        "inputkal1 = pd.DataFrame(np.nan, index=range(419), columns=range(8))\n",
        "N=kalpre.shape[0]\n",
        "St=np.zeros(N) # as we are starting from kalman filter, St for kalman filter is 421\n",
        "SSt=np.zeros(N)\n",
        "new_delta_ct= np.zeros((N, 1))\n",
        "delta_y_mean = np.zeros((5,1))\n",
        "for i in range(5):\n",
        "    delta_y_mean[i-1,0] = np.mean(kalpre[:, i + 2]) #used in generating delta in appendix 7\n",
        "E=np.array([1,0,0]) #used in generating delta in appendix 7\n",
        "sample_ct=np.zeros((N, 1))\n",
        "regime=np.zeros((N, 1))\n",
        "\n",
        "from numpy.random import normal\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import norm, gamma, beta\n",
        "import warnings\n",
        "\n",
        "# Remove warning message of time series from each iteration\n",
        "def custom_warning_handler(*args, **kwargs):\n",
        "    pass\n",
        "\n",
        "warnings.showwarning = custom_warning_handler\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##############################################################################\n",
        "#Start iteration here\n",
        "##############################################################################\n",
        "\n",
        "for i in range(iter):\n",
        "\n",
        "# First part of MCMC------- Kalman Filter\n",
        "\n",
        "##############################\n",
        "\n",
        "    N=kalpre.shape[0]   # length of data\n",
        "# Use the parameters from last iteration\n",
        "# we need new A,R,H\n",
        "#    R = np.array([\n",
        "#                 [sig1**2, 0, 0, 0, 0],\n",
        "#                 [0, sig2**2, 0, 0, 0],\n",
        "#                 [0, 0, sig3**2, 0, 0],\n",
        "#                 [0, 0, 0, sig4**2, 0],\n",
        "#                 [0, 0, 0, 0, sig5**2]\n",
        "#                 ])\n",
        "    R = np.array([[sig1.item()**2, 0, 0, 0, 0],\n",
        "              [0, sig2.item()**2, 0, 0, 0],\n",
        "              [0, 0, sig3.item()**2, 0, 0],\n",
        "              [0, 0, 0, sig4.item()**2, 0],\n",
        "              [0, 0, 0, 0, sig5.item()**2]])\n",
        "\n",
        "#observation noise, variance matrix of [epsilon 1,epsilon 2,epsilon 3,epsilon 4,epsilon 5]\n",
        "    #R = np.array([[i[0][0] if isinstance(i, np.ndarray) else i for i in row] for row in R])\n",
        "\n",
        "# variance sig_12345 are updated every iteration\n",
        "\n",
        "\n",
        "    phi[0]=np.random.normal(meanphi[0], np.sqrt(varphi[0, 0]))\n",
        "    phi[1]=np.random.normal(meanphi[1], np.sqrt(varphi[1, 1]))#new phi generated from last iteration\n",
        "    A = np.array([[phi[0], phi[1], 0],\n",
        "              [0, phi[0], phi[1]],\n",
        "              [0, 1, 0]])\n",
        "   #np.array([[phi1,phi2,0],\n",
        "   #          [0,phi1,phi2],\n",
        "   #          [0,  1,    0]])\n",
        "   # generate new psi from last iteration\n",
        "    psi[0,0]=np.random.normal(meanpsi1[0], np.sqrt(varpsi1[0, 0]))\n",
        "    psi[0,1]=np.random.normal(meanpsi1[1], np.sqrt(varpsi1[1, 1]))\n",
        "    psi[1,0]=np.random.normal(meanpsi2[0], np.sqrt(varpsi2[0, 0]))\n",
        "    psi[1,1]=np.random.normal(meanpsi2[1], np.sqrt(varpsi2[1, 1]))\n",
        "    psi[2,0]=np.random.normal(meanpsi3[0], np.sqrt(varpsi3[0, 0]))\n",
        "    psi[2,1]=np.random.normal(meanpsi3[1], np.sqrt(varpsi3[1, 1]))\n",
        "    psi[3,0]=np.random.normal(meanpsi4[0], np.sqrt(varpsi4[0, 0]))\n",
        "    psi[3,1]=np.random.normal(meanpsi4[1], np.sqrt(varpsi4[1, 1]))\n",
        "    psi[4,0]=np.random.normal(meanpsi5[0], np.sqrt(varpsi5[0, 0]))\n",
        "    psi[4,1]=np.random.normal(meanpsi5[1], np.sqrt(varpsi5[1, 1]))\n",
        "\n",
        "\n",
        "    H = np.array([\n",
        "    [np.random.normal(meanlamda1, np.sqrt(varlamda1)), -np.random.normal(meanlamda1, np.sqrt(varlamda1)) * psi[0, 0], -np.random.normal(meanlamda1, np.sqrt(varlamda1)) * psi[0, 1]],\n",
        "    [np.random.normal(meanlamda2, np.sqrt(varlamda2)), -np.random.normal(meanlamda2, np.sqrt(varlamda2)) * psi[1, 0], -np.random.normal(meanlamda2, np.sqrt(varlamda2)) * psi[1, 1]],\n",
        "    [np.random.normal(meanlamda3, np.sqrt(varlamda3)), -np.random.normal(meanlamda3, np.sqrt(varlamda3)) * psi[2, 0], -np.random.normal(meanlamda3, np.sqrt(varlamda3)) * psi[2, 1]],\n",
        "    [np.random.normal(meanlamda4, np.sqrt(varlamda4)), -np.random.normal(meanlamda4, np.sqrt(varlamda4)) * psi[3, 0], -np.random.normal(meanlamda4, np.sqrt(varlamda4)) * psi[3, 1]],\n",
        "    [np.random.normal(meanlamda5, np.sqrt(varlamda5)), -np.random.normal(meanlamda5, np.sqrt(varlamda5)) * psi[4, 0], -np.random.normal(meanlamda5, np.sqrt(varlamda5)) * psi[4, 1]]\n",
        "])\n",
        "    H = np.squeeze(H)\n",
        "\n",
        "\n",
        "\n",
        "#H = np.array([[lamda[0,0], -lamda[0,0]*psi[0, 0], -lamda[0,0]*psi[0, 1]],\n",
        "#              [lamda[0,1], -lamda[0,1]*psi[1, 0], -lamda[0,1]*psi[1, 1]],\n",
        "#              [lamda[0,2], -lamda[0,2]*psi[2, 0], -lamda[0,2]*psi[2, 1]],\n",
        "#              [lamda[0,3], -lamda[0,3]*psi[3, 0], -lamda[0,3]*psi[3, 1]],\n",
        "#              [lamda[0,4], -lamda[0,4]*psi[4, 0], -lamda[0,4]*psi[4, 1]]]) all lamda and psi come from random sampling from last iteration\n",
        "\n",
        "    P = 0.1 * np.eye(3)# initial setting of variance matrix of xi_t\n",
        "    z = np.ones((5, N))\n",
        "# Construct delta_y* using new psi\n",
        "    ystar = y.T - np.multiply(psi[:, 0].T, y1lag[0:5, :].T)- np.multiply(psi[:, 1].T,y2lag[0:5, :].T)\n",
        "    ystar=ystar.T\n",
        "    true5D = ystar\n",
        "#form new mu_st\n",
        "    St=SSt\n",
        "    #mu_st = np.random.normal(meanmu[0], np.sqrt(varmu[0,0]))*np.ones(N) + np.random.normal(meanmu[1], np.sqrt(varmu[1,1]))*np.ones(N) * St\n",
        "    mu_st = (mu0 * np.ones(N) + mu1 * np.ones(N) * St\n",
        "    )\n",
        "    phimu_st=np.zeros(N)\n",
        "    phimu_st = (mu_st[2:N]\n",
        "            - np.dot(mu_st[1:N-1], np.random.normal(meanphi[0], np.sqrt(varphi[0, 0]), size=(N-2, 1)))\n",
        "            - np.dot(mu_st[0:N-2], np.random.normal(meanphi[1], np.sqrt(varphi[1, 1]), size=(N-2, 1))))\n",
        "    phimu_st = np.array(phimu_st)\n",
        "    phimu_st = np.insert(phimu_st, [0, 0], phimu_st[0])\n",
        "    phimu_st = np.where(np.abs(phimu_st) > 10, 0, phimu_st)\n",
        "    Mu_st=np.zeros((3,N))\n",
        "    Mu_st[0,:]=phimu_st\n",
        "    Mu_st[1,1:N]=phimu_st[0:N-1]\n",
        "\n",
        "#start kalman filter\n",
        "    k = 0\n",
        "    for t in range(N-1):\n",
        "        k += 1\n",
        "        x[:, k] = np.dot(A, x[:, k-1])+Mu_st[:,k]    # Kalman equation 1\n",
        "        P = np.dot(A, np.dot(P, A.T)) +Q_kal #np.dot(B,np.dot(Q,B.T))  # Kalman equation 2\n",
        "        Hh=np.dot(H, np.dot(P, H.T)) + R\n",
        "        K = np.dot(P, np.dot(H.T, np.linalg.inv(Hh)))  # Kalman equation 3\n",
        "        z[:, k] = [true5D[0, k], true5D[1, k], true5D[2, k], true5D[3, k], true5D[4, k]]\n",
        "        x[:, k] = x[:, k] + np.dot(K, (z[:, k] - np.dot(H, x[:, k])))  # Kalman equation 4\n",
        "        P = np.dot((np.eye(3) - np.dot(K, H)), P)  # Kalman equation 5\n",
        "        vct[0, k] = P[0, 0]  # save variance of delta_ct\n",
        "        vct[1, k] = P[1, 1]\n",
        "        vct[2, k] = P[2, 2]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "###########################################################################\n",
        "# add t+1 data to information set\n",
        "\n",
        "\n",
        "    c = normal(x[0, N-1], np.sqrt(vct[0, N-1]))  # generate delta_c_T\n",
        "    xi = np.zeros((1, N))\n",
        "    V = np.zeros((1, N))\n",
        "    for ii in range(N-2):  # this loop is just for xi_t and V_t conditional on delta_ct+1 for t=1,2,...,T-1\n",
        "        eta = c - phi[0]*x[0, N-ii-2] - phi[1]*x[1, N-ii-2] - phimu_st[N-ii-1]  # value of eta_t two lag in my model, that's why I have term -phi(2)*x(2,N-i)\n",
        "        Rt = np.sum(A[0]*vct[:, N-ii-1]*A[0])+var_vt\n",
        "        xi[0, N-ii-2] = x[0, N-ii-2] + (phi[0]*vct[0, N-ii-2]+phi[1]*vct[1,N-ii-2])*eta/Rt\n",
        "    # we only use first row of the mean and variance vector\n",
        "    # so I calculated the first element of each mean & variance directly\n",
        "        V[0, N-ii-2] = vct[0, N-ii-2] - (phi[0]**2 * (vct[0,N-ii-2]**2)+phi[1]**2*(vct[1,N-ii-2]**2)) / Rt\n",
        "        if V[0, N-ii-2]<0:\n",
        "           V[0, N-ii-2]=0\n",
        "        c = normal(xi[0, N-ii-2], np.sqrt(V[0, N-ii-2]))\n",
        "    V[0, N-1] = vct[0, N-1]# V_T didn't get upgraded, it's still from step 1\n",
        "    xi[0, N-1] = x[0, N-1]# xi_T didn't get upgraded, it's still from step 1\n",
        "\n",
        "########################\n",
        "# generate new delta_ct based on new mean and variance\n",
        "\n",
        "    for iii in range(0, N):\n",
        "        new_delta_ct[iii] = np.mean(normal(xi[0,iii], np.sqrt(V[0,iii]),1000)) # new delta_c_t\n",
        "  #  new_delta_ct=xi[0,:] easier option for new_delta_ct\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##############################################################\n",
        "############# Second step of MCMC-------- Hamilton (1989) basic filter\n",
        "\n",
        "\n",
        "\n",
        "# Use output from Kalman filter to generate regime probability then generate St\n",
        "# Load the new data.\n",
        "    if i>100:\n",
        "      new_delta_ct[0]=new_delta_ct[1]#kalman filter don't update t=1\n",
        "      data= new_delta_ct.flatten()\n",
        "    else:\n",
        "      data=kalpre[:,0]\n",
        "    #data= new_delta_ct.flatten()\n",
        "#change above data to ct from above\n",
        "# Create date range\n",
        "\n",
        "    date_range = pd.date_range(start='1986-02', end='2021-03', freq='M')\n",
        "\n",
        "# Create DataFrame with date range and data\n",
        "    df = pd.DataFrame({'date': date_range, 'delta_ct': data})\n",
        "    df.set_index('date', inplace=True)\n",
        "\n",
        "\n",
        "# Fit the model\n",
        "    mod = sm.tsa.MarkovRegression(\n",
        "        df['delta_ct'], k_regimes=2, trend=\"n\", switching_variance=True\n",
        ")\n",
        "    res = mod.fit()\n",
        "\n",
        "    # res.smoothed_marginal_probabilities[1] # recession probability\n",
        "# Attention: this is time series data\n",
        "# put it back to normal later\n",
        "# if >0.5, recession probability, for K&N (1998), for UK CLI, >0.1\n",
        "# standard is not fixed, for some US recession signal, standard is >0.4\n",
        "    St = (res.smoothed_marginal_probabilities[1] <= 0.1).astype(int)\n",
        "    SSt = St.reset_index(drop=True)#new St\n",
        "    St=SSt[2:N].to_numpy().reshape(-1,1)# for estimating parameters\n",
        "    # SSt will be set back to St at the start of next iteration for kalman filter\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "###########################################################################\n",
        "# etimating parameters through gibbs sampling\n",
        "\n",
        "# St is ready, we now prepare kalpre1\n",
        "\n",
        "\n",
        "########\n",
        "#pay attention:  the name of data Y_it\n",
        "#                length modification of n (considering we are)\n",
        "# n for code below is 419, for code above is 421, make modefication of this\n",
        "##as for independent code for below area, seperate & prepared data with 419 row is given\n",
        "# now we are using data with 421 row generated above, modify this\n",
        "# for convience, still make new data into 'inputkal1'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Convert new_delta_ct to numpy array if it's a pandas DataFrame or Series\n",
        "#    new_delta_ct = new_delta_ct.values\n",
        "\n",
        "# Fill the first three columns with t, t-1, t-2 data from 'new_delta_ct'\n",
        "    for iiii in range(3):\n",
        "        inputkal1.iloc[:, iiii] = new_delta_ct[2 - iiii:421 - iiii]  # 419 values\n",
        "\n",
        "# Fill the columns 4 to 8 with the data from 'kalpre'\n",
        "    for iiii in range(3, 8):\n",
        "        inputkal1.iloc[:, iiii] = kalpre[2:422, iiii] # 419 values\n",
        "\n",
        "\n",
        "\n",
        "    righta3 = inputkal1.iloc[:, 0].T\n",
        "    N = inputkal1.shape[0]\n",
        "   # As this code is a mixture of three independent code, unavoidabely there are repeated variables\n",
        "   #such as N, to avoid troubles (as N used in too many places), we will modify the value of N in the loop\n",
        "# Section 1\n",
        "# form psi(L)*delta_y\n",
        "    ys1 = (inputkal1.iloc[2:N, 3].values - inputkal1.iloc[1:N-1, 3].values * Psi1[:, 0] - inputkal1.iloc[0:N-2, 3].values * Psi1[:, 1]).reshape(-1, 1)\n",
        "    ys2 = (inputkal1.iloc[2:N, 4].values - inputkal1.iloc[1:N-1, 4].values * Psi2[:, 0] - inputkal1.iloc[0:N-2, 4].values * Psi2[:, 1]).reshape(-1, 1)\n",
        "    ys3 = (inputkal1.iloc[2:N, 5].values - inputkal1.iloc[1:N-1, 5].values * Psi3[:, 0] - inputkal1.iloc[0:N-2, 5].values * Psi3[:, 1]).reshape(-1, 1)\n",
        "    ys4 = (inputkal1.iloc[2:N, 6].values - inputkal1.iloc[1:N-1, 6].values * Psi4[:, 0] - inputkal1.iloc[0:N-2, 6].values * Psi4[:, 1]).reshape(-1, 1)\n",
        "    ys5 = (inputkal1.iloc[2:N, 7].values - inputkal1.iloc[1:N-1, 7].values * Psi5[:, 0] - inputkal1.iloc[0:N-2, 7].values * Psi5[:, 1]).reshape(-1, 1)\n",
        "\n",
        "# delta C*~\n",
        "    rrighta3 = (righta3[2:N].values - righta3[1:N-1].values * Psi1[:, 0] - righta3[0:N-2].values * Psi1[:, 1]).reshape(-1, 1)\n",
        "\n",
        "# posterior distribution of lamda mean\n",
        "\n",
        "    meanlamda1 = 1 / (rrighta3.T @ rrighta3 / (sig1 ** 2) + 1 / varlamda1) * (meanlamda1 / varlamda1 + rrighta3.T @ ys1 / (sig1 ** 2))\n",
        "    meanlamda2 = 1 / (rrighta3.T @ rrighta3 / (sig2 ** 2) + 1 / varlamda2) * (meanlamda2 / varlamda2 + rrighta3.T @ ys2 / (sig2 ** 2))\n",
        "    meanlamda3 = 1 / (rrighta3.T @ rrighta3 / (sig3 ** 2) + 1 / varlamda3) * (meanlamda3 / varlamda3 + rrighta3.T @ ys3 / (sig3 ** 2))\n",
        "    meanlamda4 = 1 / (rrighta3.T @ rrighta3 / (sig4 ** 2) + 1 / varlamda4) * (meanlamda4 / varlamda4 + rrighta3.T @ ys4 / (sig4 ** 2))\n",
        "    meanlamda5 = 1 / (rrighta3.T @ rrighta3 / (sig5 ** 2) + 1 / varlamda5) * (meanlamda5 / varlamda5 + rrighta3.T @ ys5 / (sig5 ** 2))\n",
        "\n",
        "# posterior distribution of lamda variance\n",
        "    varlamda1 = 1 / (rrighta3.T @ rrighta3 / (sig1 ** 2) + 1 / varlamda1)\n",
        "    varlamda2 = 1 / (rrighta3.T @ rrighta3 / (sig2 ** 2) + 1 / varlamda2)\n",
        "    varlamda3 = 1 / (rrighta3.T @ rrighta3 / (sig3 ** 2) + 1 / varlamda3)\n",
        "    varlamda4 = 1 / (rrighta3.T @ rrighta3 / (sig4 ** 2) + 1 / varlamda4)\n",
        "    varlamda5 = 1 / (rrighta3.T @ rrighta3 / (sig5 ** 2) + 1 / varlamda5)\n",
        "\n",
        "    if np.isnan(meanlamda1).any() or abs(1/varlamda1)>10**6 or abs(1/varlamda2)>10**6 or abs(1/varlamda3)>10**6or abs(1/varlamda4)>10**6 or abs(1/varlamda5)>10**6:\n",
        "    # If so, replace all nan values with 0\n",
        "      meanlamda1=meanlamda2=meanlamda3=meanlamda4=meanlamda5=0\n",
        "      varlamda1=varlamda2=varlamda3=varlamda4=varlamda5=1\n",
        "\n",
        "#generate new lamda using new mean & new variance\n",
        "    lamda_1 = np.random.normal(meanlamda1, np.sqrt(varlamda1), (N, 1))\n",
        "    lamda_2 = np.random.normal(meanlamda2, np.sqrt(varlamda2), (N, 1))\n",
        "    lamda_3 = np.random.normal(meanlamda3, np.sqrt(varlamda3), (N, 1))\n",
        "    lamda_4 = np.random.normal(meanlamda4, np.sqrt(varlamda4), (N, 1))\n",
        "    lamda_5 = np.random.normal(meanlamda5, np.sqrt(varlamda5), (N, 1))\n",
        "\n",
        "# Section 2\n",
        "# generate new psi\n",
        "# Form Z and X as shown in the algorithm overview\n",
        "    Z1 = inputkal1.iloc[:, 3].values - inputkal1.iloc[:, 0].values * lamda_1.flatten()\n",
        "    Z2 = inputkal1.iloc[:, 4].values - inputkal1.iloc[:, 0].values * lamda_2.flatten()\n",
        "    Z3 = inputkal1.iloc[:, 5].values - inputkal1.iloc[:, 0].values * lamda_3.flatten()\n",
        "    Z4 = inputkal1.iloc[:, 6].values - inputkal1.iloc[:, 0].values * lamda_4.flatten()\n",
        "    Z5 = inputkal1.iloc[:, 7].values - inputkal1.iloc[:, 0].values * lamda_5.flatten()\n",
        "\n",
        "    X1 = np.column_stack((Z1[1:N - 1], Z1[:N - 2]))\n",
        "    X2 = np.column_stack((Z2[1:N - 1], Z2[:N - 2]))\n",
        "    X3 = np.column_stack((Z3[1:N - 1], Z3[:N - 2]))\n",
        "    X4 = np.column_stack((Z4[1:N - 1], Z4[:N - 2]))\n",
        "    X5 = np.column_stack((Z5[1:N - 1], Z5[:N - 2]))\n",
        "\n",
        "#save variance value of psi from last iteration for calculating mean of psi\n",
        "#as variance would get upgraded before calculating mean\n",
        "\n",
        "#    fvarpsi1 = varpsi1\n",
        "#    fvarpsi2 = varpsi2\n",
        "#    fvarpsi3 = varpsi3\n",
        "#    fvarpsi4 = varpsi4\n",
        "#    fvarpsi5 = varpsi5\n",
        "\n",
        "# form varpsi^-1 for the variance matrix from last iteration\n",
        "# as a part of calculation for posterior distribution\n",
        "#    ffvarpsi1 = np.linalg.pinv(varpsi1) #var(psi)^(-1)\n",
        "#    ffvarpsi2 = np.linalg.pinv(varpsi2)\n",
        "#    ffvarpsi3 = np.linalg.pinv(varpsi3)\n",
        "#    ffvarpsi4 = np.linalg.pinv(varpsi4)\n",
        "#    ffvarpsi5 = np.linalg.pinv(varpsi5)\n",
        "\n",
        "    fvarpsi1 = np.linalg.pinv(varpsi1) + X1.T @ X1 / (sig1 ** 2)\n",
        "    fvarpsi2 = np.linalg.pinv(varpsi2) + X2.T @ X2 / (sig2 ** 2)\n",
        "    fvarpsi3 = np.linalg.pinv(varpsi3) + X3.T @ X3 / (sig3 ** 2)\n",
        "    fvarpsi4 = np.linalg.pinv(varpsi4) + X4.T @ X4 / (sig4 ** 2)\n",
        "    fvarpsi5 = np.linalg.pinv(varpsi5) + X5.T @ X5 / (sig5 ** 2)\n",
        "# Check for NaNs and the condition\n",
        "    if np.isnan(fvarpsi1).any() or (np.isnan(fvarpsi1[0,0]*fvarpsi1[1,1]-fvarpsi1[0,1]*fvarpsi1[0,1])):\n",
        "      fvarpsi1 = np.array([[1,0],[0,1]])\n",
        "    if np.isnan(fvarpsi2).any() or (np.isnan(fvarpsi2[0,0]*fvarpsi2[1,1]-fvarpsi2[0,1]*fvarpsi2[0,1])):\n",
        "      fvarpsi2 = np.array([[1,0],[0,1]])\n",
        "    if np.isnan(fvarpsi3).any() or (np.isnan(fvarpsi3[0,0]*fvarpsi3[1,1]-fvarpsi3[0,1]*fvarpsi3[0,1])):\n",
        "      fvarpsi3 = np.array([[1,0],[0,1]])\n",
        "    if np.isnan(fvarpsi4).any() or (np.isnan(fvarpsi4[0,0]*fvarpsi4[1,1]-fvarpsi4[0,1]*fvarpsi4[0,1])):\n",
        "      fvarpsi4 = np.array([[1,0],[0,1]])\n",
        "    if np.isnan(fvarpsi5).any() or (np.isnan(fvarpsi5[0,0]*fvarpsi5[1,1]-fvarpsi5[0,1]*fvarpsi5[0,1])):\n",
        "      fvarpsi5 = np.array([[1,0],[0,1]])\n",
        "\n",
        "# posterior mean of psi\n",
        "    meanpsi1 = np.dot(np.linalg.pinv(fvarpsi1) , (np.linalg.pinv(varpsi1)@ meanpsi1 + (X1.T @ Z1[2:N]).reshape(-1, 1) / (sig1 ** 2)))\n",
        "    meanpsi2 = np.dot(np.linalg.pinv(fvarpsi2) , (np.linalg.pinv(varpsi2)@ meanpsi2 + (X2.T @ Z2[2:N]).reshape(-1, 1) / (sig2 ** 2)))\n",
        "    meanpsi3 = np.dot(np.linalg.pinv(fvarpsi3) , (np.linalg.pinv(varpsi3)@ meanpsi3 + (X3.T @ Z3[2:N]).reshape(-1, 1) / (sig3 ** 2)))\n",
        "    meanpsi4 = np.dot(np.linalg.pinv(fvarpsi4) , (np.linalg.pinv(varpsi4)@ meanpsi4 + (X4.T @ Z4[2:N]).reshape(-1, 1) / (sig4 ** 2)))\n",
        "    meanpsi5 = np.dot(np.linalg.pinv(fvarpsi5) , (np.linalg.pinv(varpsi5)@ meanpsi5 + (X5.T @ Z5[2:N]).reshape(-1, 1) / (sig5 ** 2)))\n",
        "\n",
        "# postrior variance of psi\n",
        "    varpsi1 = np.linalg.pinv(fvarpsi1)\n",
        "    varpsi2 = np.linalg.pinv(fvarpsi2)\n",
        "    varpsi3 = np.linalg.pinv(fvarpsi3)\n",
        "    varpsi4 = np.linalg.pinv(fvarpsi4)\n",
        "    varpsi5 = np.linalg.pinv(fvarpsi5)\n",
        "\n",
        "# if NaN shows up, replace with initial setting\n",
        "    if np.isnan(meanpsi1).any() :\n",
        "      meanpsi1 = np.array([[0],[0]])\n",
        "    if np.isnan(meanpsi2).any() :\n",
        "      meanpsi2 = np.array([[0],[0]])\n",
        "    if np.isnan(meanpsi3).any() :\n",
        "      meanpsi3 = np.array([[0],[0]])\n",
        "    if np.isnan(meanpsi4).any() :\n",
        "      meanpsi4 = np.array([[0],[0]])\n",
        "    if np.isnan(meanpsi5).any() :\n",
        "      meanpsi5 = np.array([[0],[0]])\n",
        "    if np.isnan(varpsi1).any() or 1/abs(varpsi1[0,0])>10000000 :\n",
        "      varpsi1 = np.array([[1,0],[0,1]])\n",
        "    if np.isnan(varpsi2).any() or 1/abs(varpsi2[0,0])>10000000 :\n",
        "      varpsi2 = np.array([[1,0],[0,1]])\n",
        "    if np.isnan(varpsi3).any() or 1/abs(varpsi3[0,0])>10000000:\n",
        "      varpsi3 = np.array([[1,0],[0,1]])\n",
        "    if np.isnan(varpsi4).any() or 1/abs(varpsi4[0,0])>10000000:\n",
        "      varpsi4 = np.array([[1,0],[0,1]])\n",
        "    if np.isnan(varpsi5).any() or 1/abs(varpsi5[0,0])>10000000:\n",
        "      varpsi5 = np.array([[1,0],[0,1]])\n",
        "\n",
        "# sampling new psi with new mean & new variance for each psi_ij, i=1,2,3,4,5 j=1,2\n",
        "    psi_11 = np.random.normal(meanpsi1[0, :], np.sqrt(varpsi1[0, 0]), size=(N-2, 1))\n",
        "    psi_21 = np.random.normal(meanpsi2[0, :], np.sqrt(varpsi2[0, 0]), size=(N-2, 1))\n",
        "    psi_31 = np.random.normal(meanpsi3[0, :], np.sqrt(varpsi3[0, 0]), size=(N-2, 1))\n",
        "    psi_41 = np.random.normal(meanpsi4[0, :], np.sqrt(varpsi4[0, 0]), size=(N-2, 1))\n",
        "    psi_51 = np.random.normal(meanpsi5[0, :], np.sqrt(varpsi5[0, 0]), size=(N-2, 1))\n",
        "\n",
        "    psi_12 = np.random.normal(meanpsi1[1, :], np.sqrt(varpsi1[1, 1]), size=(N-2, 1))\n",
        "    psi_22 = np.random.normal(meanpsi2[1, :], np.sqrt(varpsi2[1, 1]), size=(N-2, 1))\n",
        "    psi_32 = np.random.normal(meanpsi3[1, :], np.sqrt(varpsi3[1, 1]), size=(N-2, 1))\n",
        "    psi_42 = np.random.normal(meanpsi4[1, :], np.sqrt(varpsi4[1, 1]), size=(N-2, 1))\n",
        "    psi_52 = np.random.normal(meanpsi5[1, :], np.sqrt(varpsi5[1, 1]), size=(N-2, 1))\n",
        "\n",
        "# Form new psi_ij (with size (N,1)) to psi_i as a matrix of size (N,2), first column is psi_i1, second column is psi_i2\n",
        "    Psi1 = np.column_stack((psi_11, psi_12))\n",
        "    Psi2 = np.column_stack((psi_21, psi_22))\n",
        "    Psi3 = np.column_stack((psi_31, psi_32))\n",
        "    Psi4 = np.column_stack((psi_41, psi_42))\n",
        "    Psi5 = np.column_stack((psi_51, psi_52))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Process of generating sigma_i, i=1,2,3,4,5\n",
        "\n",
        "    Xx1 = X1 * Psi1\n",
        "    Xx2 = X2 * Psi2\n",
        "    Xx3 = X3 * Psi3\n",
        "    Xx4 = X4 * Psi4\n",
        "    Xx5 = X5 * Psi5\n",
        "# sigma~IG(sig1a,sig1b), posterior sig1a=4+N/2 and it's fiexed\n",
        "# we only needs to calculate posterior sig1b\n",
        "    sig1b = 4 + 0.5 * np.dot(((Z1[2:N] - Xx1[:, 0] - Xx1[:, 1]).reshape(-1, 1)).T, (Z1[2:N] - Xx1[:, 0] - Xx1[:, 1]).reshape(-1, 1))\n",
        "    sig2b = 4 + 0.5 * np.dot(((Z2[2:N] - Xx2[:, 0] - Xx2[:, 1]).reshape(-1, 1)).T, (Z2[2:N] - Xx2[:, 0] - Xx2[:, 1]).reshape(-1, 1))\n",
        "    sig3b = 4 + 0.5 * np.dot(((Z3[2:N] - Xx3[:, 0] - Xx3[:, 1]).reshape(-1, 1)).T, (Z3[2:N] - Xx3[:, 0] - Xx3[:, 1]).reshape(-1, 1))\n",
        "    sig4b = 4 + 0.5 * np.dot(((Z4[2:N] - Xx4[:, 0] - Xx4[:, 1]).reshape(-1, 1)).T, (Z4[2:N] - Xx4[:, 0] - Xx4[:, 1]).reshape(-1, 1))\n",
        "    sig5b = 4 + 0.5 * np.dot(((Z5[2:N] - Xx5[:, 0] - Xx5[:, 1]).reshape(-1, 1)).T, (Z5[2:N] - Xx5[:, 0] - Xx5[:, 1]).reshape(-1, 1))\n",
        "\n",
        "\n",
        "# generate mew sigma_i with new sig_{i}b\n",
        "    sig1 = np.sqrt(1 / np.random.gamma(sig1a+N, 1/sig1b))\n",
        "    sig2 = np.sqrt(1 / np.random.gamma(sig2a+N, 1/sig2b))\n",
        "    sig3 = np.sqrt(1 / np.random.gamma(sig3a+N, 1/sig3b))\n",
        "    sig4 = np.sqrt(1 / np.random.gamma(sig4a+N, 1/sig4b))\n",
        "    sig5 = np.sqrt(1 / np.random.gamma(sig5a+N, 1/sig5b))\n",
        "\n",
        "    if np.isnan(sig1).any():\n",
        "    # If so, replace all nan values with 0\n",
        "      sig1=sig2=sig3=sig4=sig5=np.array([[0.2]])\n",
        "\n",
        "\n",
        "#########################################################\n",
        "# Section 3\n",
        "# generate phi\n",
        "\n",
        "# Form G and Q as shown in the overview of section 3\n",
        "    G = inputkal1.iloc[4:N, 0] - np.squeeze(mut[2:N - 2].T)\n",
        "    Q[:, 0] = inputkal1.iloc[3:N-1, 0].values - np.reshape(mut[1:N-3], (-1, 1)).T\n",
        "    Q[:, 1] = inputkal1.iloc[2:N-2, 1].values - np.reshape(mut[0:N-4], (-1, 1)).T\n",
        "    Gg = G[0:N - 4]\n",
        "\n",
        "    if np.isnan(fvarphi).any() or (np.isnan(fvarphi[0,0]*fvarphi[1,1]-fvarphi[0,1]*fvarphi[0,1])):\n",
        "      fvarphi = np.array([[1,0],[0,1]])\n",
        "# calculate posterior mean of phi\n",
        "    meanphi = np.linalg.pinv(fvarphi) @ (np.dot(Q.T, Gg.T).reshape(-1, 1) + np.linalg.pinv(varphi) @ meanphi)\n",
        "# calculate posterior variance of phi\n",
        "    varphi  = np.linalg.pinv(fvarphi)\n",
        " #   aA1 = np.array([meanphi[0] / fvarphi[0,0], meanphi[1] / fvarphi[1,1]]).reshape((2, 1))\n",
        "#    meanphi = np.linalg.inv(np.dot(Q.T, Q) +np.linalg.pinv(fvarphi) ) @ (np.dot(Q.T, Gg.T).reshape(-1, 1) + aA1)\n",
        "    if np.isnan(varphi).any() or np.isnan(meanphi).any() or abs(meanphi[0])+abs(meanphi[1])>10 or 1/abs(meanphi[0])>10**10 or (not np.isnan(varphi).any() and np.isnan(varphi[0,0]*varphi[1,1]-varphi[0,1]*varphi[0,1])):\n",
        "      varphi = np.array([[1,0],[0,1]])\n",
        "      meanphi = np.array([[0],[0]])\n",
        "\n",
        "\n",
        "      fvarphi = np.dot(Q.T, Q) + np.linalg.pinv(varphi)\n",
        "#    fvarphi = np.dot(Q.T, Q) + np.linalg.pinv(varphi)\n",
        "\n",
        "#    if np.isnan(fvarphi).any() or (np.isnan(fvarphi[0,0]*fvarphi[1,1]-fvarphi[0,1]*fvarphi[0,1])):\n",
        "#      fvarphi = np.array([[1,0],[0,1]])\n",
        "    # Check if any value in meanphi is nan\n",
        "#    if np.isnan(meanphi).any() or abs(meanmu[0])+abs(meanmu[1])>10:\n",
        "    # If so, replace all nan values with 0\n",
        "#      meanphi = np.nan_to_num(meanphi)\n",
        "#      varphi = np.array([[1,0],[0,1]])\n",
        "#      fvarphi = np.dot(Q.T, Q) + np.linalg.pinv(varphi)\n",
        "#    fff = np.linalg.pinv(fvarphi)\n",
        "# there could be some 'inf' showing up at fff[0,1] and fff[1,0]\n",
        "# so we need to reform the matrix\n",
        "# the variance is still exactly same\n",
        "# so there won't be any impact on calculating posterior distribution\n",
        "\n",
        "#    ffff = np.array([[fff[0, 0], 0], [0, fff[1, 1]]])\n",
        "\n",
        "# calculating posterior mean of phi\n",
        "#    meanphi = np.linalg.inv(np.dot(Q.T, Q) + ffff) @ (np.dot(Q.T, Gg.T).reshape(-1, 1) + aA1)\n",
        "# sampling new phi\n",
        "    phi_1 = np.random.normal(meanphi[0], np.sqrt(varphi[0, 0]), size=(N - 2, 1))\n",
        "    phi_2 = np.random.normal(meanphi[1], np.sqrt(varphi[1, 1]), size=(N - 2, 1))\n",
        "\n",
        "# generating mu\n",
        "# form G* and Q* as shown in the overview of section 3\n",
        "    Gstar = inputkal1.iloc[4:N, 0].values.reshape(-1, 1) - phi_1[2:N - 2] * inputkal1.iloc[3:N - 1, 0].values.reshape(-1, 1) - phi_2[2:N - 2] * inputkal1.iloc[2:N - 2, 0].values.reshape(-1, 1)\n",
        "    Qstar = np.zeros((N - 4, 2))\n",
        "    Qstar[:, 0] = np.ones(N-4)\n",
        "    Qstar[:, 1] = (St[4:N].flatten()\n",
        "                   - np.mean(np.random.normal(meanphi[0],np.sqrt(varphi[0,0]),1000))*np.ones(N-4) * St[3:N - 1].flatten()\n",
        "                   - np.mean(np.random.normal(meanphi[1],np.sqrt(varphi[1,1]),1000))*np.ones(N-4) * St[2:N - 2].flatten()).reshape(-1,)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#   fvarmu=np.array([[np.linalg.inv(varmu)[0,0],0],[0,np.linalg.inv(varmu)[1,1]]])\n",
        "# generate posterior mean value of mu\n",
        "#    fvarmu=np.array([[np.linalg.inv(varmu)[0,0],0],[0,np.linalg.inv(varmu)[1,1]]])\n",
        "    meanmu = np.linalg.inv(np.linalg.inv(varmu) + Qstar.T @ Qstar) @ (np.linalg.inv(varmu) @ meanmu  + Qstar.T @ Gstar)\n",
        "\n",
        "# generate posterior variance of mu\n",
        "    varmu  = np.linalg.inv(np.linalg.inv(varmu) + Qstar.T @ Qstar)\n",
        "\n",
        "    if np.isnan(meanmu).any() or meanmu[1]<0 or abs(meanmu[0])>10:\n",
        "    # If so, replace all nan values with 0\n",
        "      meanmu = np.array([[-1],[1]])\n",
        "      varmu  = np.array([[1,0],[0,1]])\n",
        "\n",
        "\n",
        "# attention, this distribution for mu_o* and mu_1, so we need to calculate mu_0\n",
        "# mu_0*=mu_0(1-phi1-phi2)\n",
        "#    meanmu = np.array([[meanmu[0].item()/(\n",
        "#        1-np.random.normal(meanphi[0], np.sqrt(varphi[0, 0])).item()\n",
        "#        -np.random.normal(meanphi[1], np.sqrt(varphi[1, 1])).item())],[meanmu[1].item()]])\n",
        "#    varmu=np.vectorize(float)(np.array([[varmu[0,0]/(\n",
        "#        (1-np.random.normal(meanphi[0], np.sqrt(varphi[0, 0])).item()\n",
        "#        -np.random.normal(meanphi[1], np.sqrt(varphi[1, 1])).item())**2),0],[0, varmu[1,1]]]))\n",
        "# attention, this distribution for mu_o* and mu_1, so we need to calculate mu_0\n",
        "# mu_0*=mu_0(1-phi1-phi2)\n",
        " #   meanmu[0] = meanmu[0]/(\n",
        " #       1-np.random.normal(meanphi[0], np.sqrt(varphi[0, 0])))\n",
        " #   varmu[0,0]=varmu[0,0]/(\n",
        " #       (1-np.random.normal(meanphi[0], np.sqrt(varphi[0, 0]))\n",
        " #       -np.random.normal(meanphi[1], np.sqrt(varphi[1, 1])))**2)\n",
        "#    if  abs(mu0)+abs(meanmu[1])>10: # mu0 and mu1 are very small value about 0.1 according to test\n",
        "#      mu0= -1\n",
        "#      meanmu=np.array([[-1],[1]])\n",
        "#      varmu=np.array([[1,0],[0,1]])\n",
        "# generate mu0\n",
        "    mu0=(np.mean(np.random.normal(meanmu[0], np.sqrt(varmu[0, 0]),1000))/(1\n",
        "         -np.mean(np.random.normal(meanphi[0], np.sqrt(varphi[0, 0]),1000))\n",
        "         - np.mean(np.random.normal(meanphi[1], np.sqrt(varphi[1, 1]),1000))))\n",
        "    if  abs(mu0)>2:\n",
        "      mu0=-1\n",
        "    if mu1 > 2:\n",
        "      mu1=1\n",
        "    mu1=np.mean(np.random.normal(meanmu[1], np.sqrt(varmu[1, 1]),1000))\n",
        "    mut =( mu0 * np.ones(N)\n",
        "        + mu1 * np.ones(N) * St.flatten().flatten()\n",
        "    )\n",
        "\n",
        "\n",
        "    mut =( mu0 * np.ones(N)\n",
        "        + mu1 * np.ones(N) * St.flatten().flatten()\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# delta\n",
        "#    newdelta=np.dot(E,np.dot(np.linalg.inv(K[:,0:3]-np.dot((np.eye(3)-np.dot(K,H)),A)),np.dot(K,delta_y_mean)))\n",
        "\n",
        "# same value of each iteration after first 2000 iterations\n",
        "    if i>burn-1:\n",
        "\n",
        "#########################################################################\n",
        "\n",
        "#      p_00 = res.params[0]    #### this is q: recession to recession P(S_t=0|S_t-1=0)\n",
        "#      p_11 = 1-res.params[1]  #### this is p: expansion to expansion P(S_t=1|S_t-1=1)\n",
        "#.     generated by Markov switching package in paython, no need to calculate by ourselves\n",
        "      # delta\n",
        "      newdelta=np.dot(E,np.dot(np.linalg.inv(K[:,0:3]-np.dot((np.eye(3)-np.dot(K,H)),A)),np.dot(K,delta_y_mean)))\n",
        "\n",
        "\n",
        "      mlamda1[i - burn] = meanlamda1\n",
        "      mlamda2[i - burn] = meanlamda2\n",
        "      mlamda3[i - burn] = meanlamda3\n",
        "      mlamda4[i - burn] = meanlamda4\n",
        "      mlamda5[i - burn] = meanlamda5\n",
        "      vlamda1[i - burn] = varlamda1\n",
        "      vlamda2[i - burn] = varlamda2\n",
        "      vlamda3[i - burn] = varlamda3\n",
        "      vlamda4[i - burn] = varlamda4\n",
        "      vlamda5[i - burn] = varlamda5\n",
        "      bsig1[i - burn] = sig1\n",
        "      bsig2[i - burn] = sig2\n",
        "      bsig3[i - burn] = sig3\n",
        "      bsig4[i - burn] = sig4\n",
        "      bsig5[i - burn] = sig5\n",
        "      mpsi11[i - burn] = meanpsi1[0, 0]\n",
        "      mpsi21[i - burn] = meanpsi2[0, 0]\n",
        "      mpsi31[i - burn] = meanpsi3[0, 0]\n",
        "      mpsi41[i - burn] = meanpsi4[0, 0]\n",
        "      mpsi51[i - burn] = meanpsi5[0, 0]\n",
        "      mpsi12[i - burn] = meanpsi1[1, 0]\n",
        "      mpsi22[i - burn] = meanpsi2[1, 0]\n",
        "      mpsi32[i - burn] = meanpsi3[1, 0]\n",
        "      mpsi42[i - burn] = meanpsi4[1, 0]\n",
        "      mpsi52[i - burn] = meanpsi5[1, 0]\n",
        "      vpsi11[i - burn] = varpsi1[0, 0]\n",
        "      vpsi21[i - burn] = varpsi2[0, 0]\n",
        "      vpsi31[i - burn] = varpsi3[0, 0]\n",
        "      vpsi41[i - burn] = varpsi4[0, 0]\n",
        "      vpsi51[i - burn] = varpsi5[0, 0]\n",
        "      vpsi12[i - burn] = varpsi1[1, 1]\n",
        "      vpsi22[i - burn] = varpsi2[1, 1]\n",
        "      vpsi32[i - burn] = varpsi3[1, 1]\n",
        "      vpsi42[i - burn] = varpsi4[1, 1]\n",
        "      vpsi52[i - burn] = varpsi5[1, 1]\n",
        "      mphi1[i - burn] = meanphi[0, 0]\n",
        "      mphi2[i - burn] = meanphi[1, 0]\n",
        "      vphi1[i - burn] = varphi[0, 0]\n",
        "      vphi2[i - burn] = varphi[1, 1]\n",
        "      mmu1[i - burn] = meanmu[0, 0]\n",
        "      mmu2[i - burn] = meanmu[1, 0]\n",
        "      vmu1[i - burn] = varmu[0, 0]\n",
        "      vmu2[i - burn] = varmu[1, 1]\n",
        "      transition_prob_p[i-burn]=1-res.params[1]  #### this is p: expansion to expansion P(S_t=1|S_t-1=1)\n",
        "      transition_prob_q[i-burn]=res.params[0]    #### this is q: recession to recession P(S_t=0|S_t-1=0)\n",
        "      delta[i-burn]=newdelta\n",
        "      sample_ct=sample_ct+new_delta_ct\n",
        "      regime=regime+res.smoothed_marginal_probabilities[1].values.reshape(-1, 1)#will calculate mean value later"
      ],
      "metadata": {
        "id": "THRIF9CKniRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# after getting mean and variance from 8000 iterations, we take mean of 8000 iterations of mean value and variance value\n",
        "mmlamda1 = np.mean(mlamda1)\n",
        "mmlamda2 = np.mean(mlamda2)\n",
        "mmlamda3 = np.mean(mlamda3)\n",
        "mmlamda4 = np.mean(mlamda4)\n",
        "mmlamda5 = np.mean(mlamda5)\n",
        "vvlamda1 = np.mean(vlamda1)\n",
        "vvlamda2 = np.mean(vlamda2)\n",
        "vvlamda3 = np.mean(vlamda3)\n",
        "vvlamda4 = np.mean(vlamda4)\n",
        "vvlamda5 = np.mean(vlamda5)\n",
        "mbsig1 = np.mean(bsig1)\n",
        "mbsig2 = np.mean(bsig2)\n",
        "mbsig3 = np.mean(bsig3)\n",
        "mbsig4 = np.mean(bsig4)\n",
        "mbsig5 = np.mean(bsig5)\n",
        "mmpsi11 = np.mean(mpsi11)\n",
        "mmpsi21 = np.mean(mpsi21)\n",
        "mmpsi31 = np.mean(mpsi31)\n",
        "mmpsi41 = np.mean(mpsi41)\n",
        "mmpsi51 = np.mean(mpsi51)\n",
        "mmpsi12 = np.mean(mpsi12)\n",
        "mmpsi22 = np.mean(mpsi22)\n",
        "mmpsi32 = np.mean(mpsi32)\n",
        "mmpsi42 = np.mean(mpsi42)\n",
        "mmpsi52 = np.mean(mpsi52)\n",
        "vvpsi11 = np.mean(vpsi11)\n",
        "vvpsi21 = np.mean(vpsi21)\n",
        "vvpsi31 = np.mean(vpsi31)\n",
        "vvpsi41 = np.mean(vpsi41)\n",
        "vvpsi51 = np.mean(vpsi51)\n",
        "vvpsi12 = np.mean(vpsi12)\n",
        "vvpsi22 = np.mean(vpsi22)\n",
        "vvpsi32 = np.mean(vpsi32)\n",
        "vvpsi42 = np.mean(vpsi42)\n",
        "vvpsi52 = np.mean(vpsi52)\n",
        "mmphi1 = np.mean(mphi1)\n",
        "mmphi2 = np.mean(mphi2)\n",
        "vvphi1 = np.mean(vphi1)\n",
        "vvphi2 = np.mean(vphi2)\n",
        "mmmu1 = np.mean(mmu1)\n",
        "mmmu2 = np.mean(mmu2)\n",
        "vvmu1 = np.var(mmu1)# mmu1 saves the samples of mu1, mu1 is generated by Monte Carlo, variance would be sampled\n",
        "                     # from mu0\n",
        "vvmu2 = np.mean(vmu2)\n",
        "sqrt_var_bsig1 = np.sqrt(np.var(bsig1))\n",
        "sqrt_var_bsig2 = np.sqrt(np.var(bsig2))\n",
        "sqrt_var_bsig3 = np.sqrt(np.var(bsig3))\n",
        "sqrt_var_bsig4 = np.sqrt(np.var(bsig4))\n",
        "sqrt_var_bsig5 = np.sqrt(np.var(bsig5))\n",
        "#sigma is slightly special as it follows inverse Gamma distribution\n",
        "#but Kim & Nelson (1998) still provides the mean and SD for sigma\n",
        "# so what we do here is to calculate mean and variance of 80000 sigma_i for i=1,2,3,4,5 from 8000 iterations\n",
        "mbsig1=np.mean(bsig1)\n",
        "mbsig2=np.mean(bsig2)\n",
        "mbsig3=np.mean(bsig3)\n",
        "mbsig4=np.mean(bsig4)\n",
        "mbsig5=np.mean(bsig5)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# transition probabilities p & q\n",
        "\n",
        "meanp=np.mean(transition_prob_p)\n",
        "meanq=np.mean(transition_prob_q)\n",
        "varp=np.var(transition_prob_p)\n",
        "varq=np.var(transition_prob_q)\n",
        "\n",
        "#delta_ct\n",
        "NEW_delta_ct=sample_ct/8000\n",
        "\n",
        "#regime\n",
        "regime=regime/8000\n",
        "\n",
        "#print all results\n",
        "print(\"mean of lamda1:\", mmlamda1)\n",
        "print(\"mean of lamda2:\", mmlamda2)\n",
        "print(\"mean of lamda3:\", mmlamda3)\n",
        "print(\"mean of lamda4:\", mmlamda4)\n",
        "print(\"mean of lamda5:\", mmlamda5)\n",
        "print(\"stanard deviation of lamda1:\", np.sqrt(vvlamda1))\n",
        "print(\"stanard deviation of lamda2:\", np.sqrt(vvlamda2))\n",
        "print(\"stanard deviation of lamda3:\", np.sqrt(vvlamda3))\n",
        "print(\"stanard deviation of lamda4:\", np.sqrt(vvlamda4))\n",
        "print(\"stanard deviation of lamda5:\", np.sqrt(vvlamda5))\n",
        "print(\"mean of psi11:\", mmpsi11)\n",
        "print(\"mean of psi21:\", mmpsi21)\n",
        "print(\"mean of psi31:\", mmpsi31)\n",
        "print(\"mean of psi41:\", mmpsi41)\n",
        "print(\"mean of psi51:\", mmpsi51)\n",
        "print(\"mean of psi12:\", mmpsi12)\n",
        "print(\"mean of psi22:\", mmpsi22)\n",
        "print(\"mean of psi32:\", mmpsi32)\n",
        "print(\"mean of psi42:\", mmpsi42)\n",
        "print(\"mean of psi52:\", mmpsi52)\n",
        "print(\"stanard deviation of psi11:\", np.sqrt(vvpsi11))\n",
        "print(\"stanard deviation of psi21:\", np.sqrt(vvpsi21))\n",
        "print(\"stanard deviation of psi31:\", np.sqrt(vvpsi31))\n",
        "print(\"stanard deviation of psi41:\", np.sqrt(vvpsi41))\n",
        "print(\"stanard deviation of psi51:\", np.sqrt(vvpsi51))\n",
        "print(\"stanard deviation of psi12:\", np.sqrt(vvpsi12))\n",
        "print(\"stanard deviation of psi22:\", np.sqrt(vvpsi22))\n",
        "print(\"stanard deviation of psi32:\", np.sqrt(vvpsi32))\n",
        "print(\"stanard deviation of psi42:\", np.sqrt(vvpsi42))\n",
        "print(\"stanard deviation of psi52:\", np.sqrt(vvpsi52))\n",
        "print(\"mean of phi1:\", mmphi1)\n",
        "print(\"mean of phi2:\", mmphi2)\n",
        "print(\"stanard deviation of phi1:\", np.sqrt(vvphi1))\n",
        "print(\"stanard deviation of phi2:\", np.sqrt(vvphi2))\n",
        "print(\"mean of mu1:\", mmmu1)\n",
        "print(\"mean of mu2:\", mmmu2)\n",
        "print(\"stanard deviation of mu1:\", np.sqrt(vvmu1))\n",
        "print(\"stanard deviation of mu2:\", np.sqrt(vvmu2))\n",
        "print(\"stanard deviation of sigma1:\", sqrt_var_bsig1)\n",
        "print(\"stanard deviation of sigma2:\", sqrt_var_bsig2)\n",
        "print(\"stanard deviation of sigma3:\", sqrt_var_bsig3)\n",
        "print(\"stanard deviation of sigma4:\", sqrt_var_bsig4)\n",
        "print(\"stanard deviation of sigma5:\", sqrt_var_bsig5)\n",
        "print(\"mean of sigma1:\", mbsig1)\n",
        "print(\"mean of sigma2:\", mbsig2)\n",
        "print(\"mean of sigma3:\", mbsig3)\n",
        "print(\"mean of sigma4:\", mbsig4)\n",
        "print(\"mean of sigma5:\", mbsig5)\n",
        "print(\"mean of p:\", meanp)\n",
        "print(\"var of p:\", varp)\n",
        "print(\"mean of q:\", meanq)\n",
        "print(\"var of q:\", varq)\n",
        "print(\"mean of delta:\", np.mean(delta))\n",
        "print(\"var of delta:\", np.var(delta))"
      ],
      "metadata": {
        "id": "TTwWC8_AnwR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################\n",
        "####### plot of recession probability\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# Create a new DataFrame to store the ratios\n",
        "date_range_ratios = pd.date_range(start='1986-02', end='2021-03', freq='M')\n",
        "df_ratios = pd.DataFrame({'date': date_range_ratios, 'ratio': regime.ravel()})\n",
        "df_ratios.set_index('date', inplace=True)\n",
        "\n",
        "# Plot the ratio series\n",
        "df_ratios['ratio'].plot(title=\"Recession\", figsize=(20, 3))\n",
        "plt.ylim(0, 1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HWdqfA2Knz-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy.random import normal\n",
        "N=kalpre.shape[0]\n",
        "ddelta=np.mean(delta)\n",
        "C0=99.72203\n",
        "newCLI = np.zeros((N, 1))\n",
        "newCLI[0]=C0+(sample_ct/8000)[0]\n",
        "for i in range(1, N):\n",
        "    newCLI[i] = newCLI[i-1] +  (sample_ct/8000)[i] # new delta_C_t=delta_c_t+C_{t-1}+delta according to appendix A7\n",
        "    # Create an array of monthly dates\n",
        "dates = pd.date_range(start='1986-03-01', end='2021-3-01', freq='MS')\n",
        "\n",
        "# Create a pandas Series with the data and the dates as index\n",
        "series1 = pd.Series(data=newCLI.ravel(), index=dates)\n",
        "fig, ax = plt.subplots(figsize=(10,3))\n",
        "# Plot the series\n",
        "series1.plot(figsize=(20,3), legend=False,label='new economic index',color='orange')\n",
        "\n",
        "\n",
        "# Set the y-axis limits\n",
        "ax.set_ylim(87.5, 102.5)\n",
        "plt.legend()\n",
        "plt.savefig('myplot.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-klEyqJDn2jX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "url = 'https://raw.githubusercontent.com/Buchunwang/UK-CLI/main/Kalman%20filter/CLI_raw.csv'#original CLI data\n",
        "CLI = pd.read_csv(url, header=None, encoding='utf-8', skiprows=1)\n",
        "# Create an array of monthly dates\n",
        "dates = pd.date_range(start='1986-03-01', end='2021-3-01', freq='MS')\n",
        "\n",
        "# Create a pandas Series with the data and the dates as index\n",
        "series1 = pd.Series(data=newCLI.ravel(), index=dates)\n",
        "fig, ax = plt.subplots(figsize=(10,3))\n",
        "# Plot the series\n",
        "series1.plot(figsize=(10,3), legend=False,label='New UK economy index',color='orange')\n",
        "\n",
        "# Create another pandas Series with the same dates as index\n",
        "series2 = pd.Series(CLI.values.ravel(), index=dates)\n",
        "# Plot the series\n",
        "\n",
        "# Plot the second series\n",
        "series2.plot(figsize=(10,3), legend=False,label='CLI from OECD')\n",
        "\n",
        "\n",
        "\n",
        "# Set the y-axis limits\n",
        "#ax.set_ylim(80, 110)\n",
        "plt.legend()\n",
        "plt.savefig('myplot.png')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "sHqlE7q9n5Up"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}