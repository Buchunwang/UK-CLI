{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyxuhGURw/mzS72lpmWQsp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Buchunwang/UK-CLI/blob/main/UK_CLI_Gibbs_Sampling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the Gibbs sampling process for UK CLI data after Kalman filter and Hamilton (1989) basic filter.\n",
        "\n",
        "---\n",
        "First, we import  \n",
        "\n",
        "1.   $Δ c_t$ including $Δ c_{t-1}, Δ c_{t-2}\\ $\n",
        "2.   $Δ y_{it}$ for $i=1,2,3,4,5$  \n",
        "3.   $S_t$\n",
        "\n",
        "That's all the import for Gibbs sampling,"
      ],
      "metadata": {
        "id": "E6c4zO6JHOyX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyMv6xINOrml",
        "outputId": "5a1c905a-17fc-4def-d9a1-7a4f8fc04ad3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From URL: https://raw.githubusercontent.com/Buchunwang/UK-CLI/main/Gibbs%20Sampling/St.csv\n",
            "From URL: https://raw.githubusercontent.com/Buchunwang/UK-CLI/main/Gibbs%20Sampling/gibbspre.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "url = 'https://raw.githubusercontent.com/Buchunwang/UK-CLI/main/Gibbs%20Sampling/St.csv'\n",
        "print('From URL:', url)\n",
        "St = pd.read_csv(url, header=None, encoding='utf-8', skiprows=1)#St\n",
        "url = 'https://raw.githubusercontent.com/Buchunwang/UK-CLI/main/Gibbs%20Sampling/gibbspre.csv'\n",
        "print('From URL:', url)\n",
        "inputkal1 = pd.read_csv(url, header=None, encoding='utf-8', skiprows=1)#delta_ct delta_ct-1 delta_ct-2 delta_y_{1,2,3,4,5}t"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "iter = 10000 # number of iterations\n",
        "burn = 2000 #we burn the first 2000 iterations and sampling from the later 8000 iterations in the Monter Carlo\n",
        "N = 419  # time point, there are two lags for delta_ct, so after preparing data from 421 data points, there are 419 left\n",
        "\n",
        "#Now we begin to set the initial values of parameters wwe are going to estimate in the algorithm\n",
        "phi_1 = np.random.normal(0, 1, (N - 4, 1))\n",
        "phi_2 = np.random.normal(0, 1, (N - 4, 1))\n",
        "lamda_1 = np.random.normal(0, 1, (N, 1))\n",
        "#these are just initial settings, \n",
        "#later on we will draw samples of thses parameters by newly generated mean and variance (or other distribution parameters for other types of distribution)\n",
        "lamda_2 = np.random.normal(0, 1, (N, 1))\n",
        "lamda_3 = np.random.normal(0, 1, (N, 1))\n",
        "lamda_4 = np.random.normal(0, 1, (N, 1))\n",
        "lamda_5 = np.random.normal(0, 1, (N, 1))\n",
        "Psi1 = np.random.normal(0, 1, (N - 2, 2))\n",
        "Psi2 = np.random.normal(0, 1, (N - 2, 2))\n",
        "Psi3 = np.random.normal(0, 1, (N - 2, 2))\n",
        "Psi4 = np.random.normal(0, 1, (N - 2, 2))\n",
        "Psi5 = np.random.normal(0, 1, (N - 2, 2))\n",
        "rrighta3 = np.zeros((1, N - 2))#this matrix is for calculating distribution of lamda\n",
        "q = np.random.binomial(0.9, 0.066)\n",
        "p = np.random.binomial(0.967, 0.032)\n",
        "sig1 = 0.2 #initial value of sigma_i\n",
        "sig2 = 0.2\n",
        "sig3 = 0.2\n",
        "sig4 = 0.2\n",
        "sig5 = 0.2\n",
        "mu0 = np.random.normal(0, 1, (N - 2, 1))\n",
        "mu1 = np.random.normal(0, 1, (N - 2, 1))\n",
        "mut = mu0 + mu1 * St[2:N] #corresponding regime for t=3 to N\n",
        "\n",
        "# variance and mean initial set\n",
        "varlamda1 = 1\n",
        "varlamda2 = 1\n",
        "varlamda3 = 1\n",
        "varlamda4 = 1\n",
        "varlamda5 = 1\n",
        "meanlamda1 = 0 #lamda_1~N(meanlamda1,varlamda1)\n",
        "meanlamda2 = 0\n",
        "meanlamda3 = 0\n",
        "meanlamda4 = 0\n",
        "meanlamda5 = 0\n",
        "varpsi1 = np.eye(2)\n",
        "varpsi2 = np.eye(2)\n",
        "varpsi3 = np.eye(2)\n",
        "varpsi4 = np.eye(2)\n",
        "varpsi5 = np.eye(2)\n",
        "meanpsi1 = np.zeros((2, 1))#psi_1~N(meanpsi1,varpsi1), meanpsi1=np.array([[a],[b]]),varpsii1=np.array([[a1,a2],[b1,b2]])\n",
        "meanpsi2 = np.zeros((2, 1))\n",
        "meanpsi3 = np.zeros((2, 1))\n",
        "meanpsi4 = np.zeros((2, 1))\n",
        "meanpsi5 = np.zeros((2, 1))\n",
        "sig1a = 4 + N / 2 #sigma_1~IG(sig1a,sig1b) inverse gamma distribution\n",
        "sig2a = 4 + N / 2\n",
        "sig3a = 4 + N / 2\n",
        "sig4a = 4 + N / 2\n",
        "sig5a = 4 + N / 2\n",
        "sig1b = 4\n",
        "sig2b = 4\n",
        "sig3b = 4\n",
        "sig4b = 4\n",
        "sig5b = 4\n",
        "X1 = np.zeros((N - 2, 2))\n",
        "X2 = np.zeros((N - 2, 2))\n",
        "X3 = np.zeros((N - 2, 2))\n",
        "X4 = np.zeros((N - 2, 2))\n",
        "X5 = np.zeros((N - 2, 2))\n",
        "varphi = np.array([[1, 0], [0, 1]])\n",
        "meanphi = np.array([0, 0])\n",
        "varmu = np.array([[1, 0], [0, 1]])\n",
        "meanmu = np.array([[0], [0]])\n",
        "Q = np.zeros((N - 4, 2))\n",
        "Qstar = np.zeros((N - 4, 2))\n",
        "\n",
        "# Output\n",
        "# We set some empty matrices here to save values from each iteration \n",
        "# After the 2000 burn-in period, we need to save value for later 80000 iterations \n",
        "mlamda1 = np.zeros(8000)\n",
        "mlamda2 = np.zeros(8000)\n",
        "mlamda3 = np.zeros(8000)\n",
        "mlamda4 = np.zeros(8000)\n",
        "mlamda5 = np.zeros(8000)\n",
        "vlamda1 = np.zeros(8000)\n",
        "vlamda2 = np.zeros(8000)\n",
        "vlamda3 = np.zeros(8000)\n",
        "vlamda4 = np.zeros(8000)\n",
        "vlamda5 = np.zeros(8000)\n",
        "bsig1 = np.zeros(8000)\n",
        "bsig2 = np.zeros(8000)\n",
        "bsig3 = np.zeros(8000)\n",
        "bsig4 = np.zeros(8000)\n",
        "bsig5 = np.zeros(8000)\n",
        "mpsi11 = np.zeros(8000)\n",
        "mpsi21 = np.zeros(8000)\n",
        "mpsi31 = np.zeros(8000)\n",
        "mpsi41 = np.zeros(8000)\n",
        "mpsi12 = np.zeros(8000)\n",
        "mpsi22 = np.zeros(8000)\n",
        "mpsi32 = np.zeros(8000)\n",
        "mpsi42 = np.zeros(8000)\n",
        "mpsi51 = np.zeros(8000)\n",
        "mpsi52 = np.zeros(8000)\n",
        "vpsi11 = np.zeros(8000)\n",
        "vpsi21 = np.zeros(8000)\n",
        "vpsi31 = np.zeros(8000)\n",
        "vpsi41 = np.zeros(8000)\n",
        "vpsi12 = np.zeros(8000)\n",
        "vpsi22 = np.zeros(8000)\n",
        "vpsi32 = np.zeros(8000)\n",
        "vpsi42 = np.zeros(8000)\n",
        "vpsi51 = np.zeros(8000)\n",
        "vpsi52 = np.zeros(8000)\n",
        "mphi1 = np.zeros(8000)\n",
        "mphi2 = np.zeros(8000)\n",
        "vphi1 = np.zeros(8000)\n",
        "vphi2 = np.zeros(8000)\n",
        "mmu1 = np.zeros(8000)\n",
        "mmu2 = np.zeros(8000)\n",
        "vmu1 = np.zeros(8000)\n",
        "vmu2 = np.zeros(8000)\n"
      ],
      "metadata": {
        "id": "WvX316CBSr0N"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the Gibbs sampling is a whole loop, we can't seperate it into blocks. So I will show the corresponding algorithms here.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "  \n",
        "    \n",
        "\n",
        "\n",
        "1.  Generating $\\lambda _i$, $i=1,2,3,4,5$\n",
        "Given $\\tilde{S}_T=\\begin{bmatrix}\n",
        "\tS_1& S_2 &\\cdots&S_T\n",
        "\\end{bmatrix}'$ from last step and $\\tilde{c}_T=\\begin{bmatrix}\n",
        "\tc_1& c_2 &\\cdots&c_T\n",
        "\\end{bmatrix}'$.  \n",
        "\n",
        "\\begin{equation}\n",
        "\ty^*_{it}=\\lambda_i\\Delta c_t^*+\\epsilon _{it}\n",
        "\\end{equation}\n",
        "where $\\Delta c^*_t=\\Psi_i(L)\\Delta c_t$ and $\\Delta y^*_t=\\Psi_i(L)\\Delta y_t$. Define $\\Delta \\tilde{C}^*$ and $\\Delta \\tilde{y}^*_i$ as variable vectors of right-hand-side and left-hand-side individually. We can then generate posterior distribution $\\lambda_i$ by:    \n",
        "  \n",
        "\n",
        "$$\n",
        "\\lambda_i \\sim N\\left(\\left(\\sigma_i^{-2} \\Delta\\tilde{C}^{\\prime} \\Delta\\tilde{C}^{\\ast} + X_i^{-1}\\right)^{-1}\\left(\\sigma_i^{-2} \\Delta\\tilde{C}^{\\prime} \\Delta\\tilde{y}_i^{\\ast} + X_i^{-1} x_i\\right), \\left(\\sigma_i^{-2} \\Delta\\tilde{C}^{\\prime} \\Delta\\tilde{C}^{\\ast} + X_i^{-1}\\right)^{-1}\\right)\n",
        "$$\n",
        "\n",
        "given prior distribution as \n",
        "\\begin{equation}\n",
        "\t\\lambda_i\\sim N(x_i,X_i)\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "2. Generating $\\psi$ and $\\sigma_i$, $i=1,2,3,4,5$\n",
        "Let $Z_t=y_{it}-\\lambda _i \\Delta c_t=e_{it}$ where $\\lambda _i$ is newly generated from last step.  \n",
        "\n",
        "\\begin{equation}\n",
        "\t\\Psi(L)Z_t=\\epsilon_{it}\n",
        "\\end{equation} \n",
        "\n",
        "\\begin{equation}\n",
        "\tZ_t=\\psi_{i1}Z_{t-1}+\\psi{i2}Z_{t-2}+\\epsilon_{it}\n",
        "\\end{equation} \n",
        "\n",
        "Define $\\Delta \\tilde{Z}$ and $\\tilde{X}$ as variable vectors of right-hand-side and left-hand-side individually. We can then generate posterior distribution $\\tilde\\Psi_i$ ($\\tilde\\Psi_i=\\begin{bmatrix}\n",
        "\t\\psi_{i1}&\\psi_{i2}\n",
        "\\end{bmatrix}'$) by:\n",
        "$$\n",
        "\\tilde{\\Psi}_i \\sim N\\left(\\left(\\sigma_i^{-2} \\tilde{X}^{\\prime} \\tilde{X}^{\\ast} + \\Pi_i^{-1}\\right)^{-1}\\left(\\sigma_i^{-2} \\tilde{X}^{\\prime} \\tilde{Z}_i^{\\ast} + \\Pi_i^{-1} \\pi_i\\right),\\left(\\sigma_i^{-2} \\tilde{X}^{\\prime} \\tilde{X}^{\\ast} + \\Pi_i^{-1}\\right)^{-1}\\right)\n",
        "$$\n",
        "\n",
        "given prior distribution as \n",
        "\\begin{equation}\n",
        "\t\\lambda_i\\sim N(\\pi _i\\Pi _i)\n",
        "\\end{equation}\n",
        "With new $\\tilde\\Psi_i$ from above,  \n",
        "\n",
        "\\begin{equation}\n",
        "\t\\sigma^2_i\\sim IG(\\frac{a+T}{2},\\frac{b}{2}+\\frac{1}{2}(\\tilde A-\\tilde Z\\tilde \\Psi_i)'(\\tilde A-\\tilde Z\\tilde \\Psi_i))\n",
        "\\end{equation}\n",
        "given prior $\\sigma^2 \\sim IG(\\frac{a}{2},\\frac{b}{2})$ where $IG$ means inverse gamma distribution. $a$ and $b$ are known value and we follow \\citet{kim2} to set $a=b=4$.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "3. Generating $\\mu_0$, $\\mu_1$ and $\\tilde \\phi$ \n",
        " To generate\n",
        "$\\tilde\\phi=\\begin{bmatrix}\\phi_1&\\phi_2\\end{bmatrix}'$, let $G_t=\\Delta c_t-\\mu_{s_t}$.   \n",
        "\n",
        "\\begin{equation}\n",
        "\tG_t=\\phi_1G_{t-1}-\\phi_2G_{t-2}+v_t\n",
        "\\end{equation}\n",
        "let $\\tilde Q$ and $\\tilde G$ be right-hand-side and left-hand-side variable vector individually.\n",
        "We can generate posterior distribution of $\\Phi$. \n",
        "\n",
        "\\begin{equation}\n",
        "\t\\tilde \\Phi\\sim N((\\tilde Q'\\tilde Q+X^{-1})^{-1}(\\tilde Q'\\tilde G+X^{-1}x),(\\tilde Q'\\tilde Q+X^{-1})^{-1})\n",
        "\\end{equation}\n",
        "given prior as \n",
        "\n",
        "\\begin{equation}\n",
        "\t\\Phi\\sim N(x,X)\n",
        "\\end{equation}\n",
        "With new $\\Phi$ above, we let $G^*=\\Delta c_t-\\phi_1\\Delta c_{t-1}-\\phi_2\\Delta c_{t-2}$, then we can get \n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "\tG^*=\\mu_0^*+\\mu_1(S_t-\\phi_1S_{t-1}-\\phi_2S_{t-2})+v_t\n",
        "\\end{equation}  \n",
        "\n",
        "where $\\mu_0^*=\\mu_0(1-\\phi_1-\\phi_2)$. Let $\\tilde Q^*$ and $\\tilde G^*$ be right-hand-side and left-hand-side variable vector individually. Posterior distribution of $\\tilde \\mu=\\begin{bmatrix}\n",
        "\t\\mu_0^*&\\mu_t\n",
        "\\end{bmatrix}$ from. \n",
        "\n",
        "$$\n",
        "\\tilde{\\mu} \\sim N\\left(\\left(\\tilde{Q}^{\\ast\\prime}\\tilde{Q}^{\\ast} + X^{*^{-1}}\\right)^{-1}\\left(\\tilde{Q}^{\\ast\\prime}\\tilde{G}^{\\ast} + X^{*^{-1}}x^{\\ast}\\right), \\left(\\tilde{Q}^{\\ast\\prime}\\tilde{Q}^{\\ast} + X^{*^{-1}}\\right)^{-1}\\right)\n",
        "$$\n",
        "\n",
        "given prior as\n",
        "\\begin{equation}\n",
        "\t\\Phi\\sim N(x^*,X^*)\n",
        "\\end{equation}"
      ],
      "metadata": {
        "id": "rw2NBE7Sp4_D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following iteration takes around 3 minutes in google colab"
      ],
      "metadata": {
        "id": "GeYJ_L6TNG6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import norm, gamma\n",
        "\n",
        "for i in range(iter):\n",
        "    righta3 = inputkal1.iloc[:, 0].T\n",
        "    N = inputkal1.shape[0]\n",
        "# Section 1\n",
        "# form psi(L)*delta_y\n",
        "    ys1 = (inputkal1.iloc[2:N, 3].values - inputkal1.iloc[1:N-1, 3].values * Psi1[:, 0] - inputkal1.iloc[0:N-2, 3].values * Psi1[:, 1]).reshape(-1, 1)\n",
        "    ys2 = (inputkal1.iloc[2:N, 4].values - inputkal1.iloc[1:N-1, 4].values * Psi2[:, 0] - inputkal1.iloc[0:N-2, 4].values * Psi1[:, 1]).reshape(-1, 1)\n",
        "    ys3 = (inputkal1.iloc[2:N, 5].values - inputkal1.iloc[1:N-1, 5].values * Psi3[:, 0] - inputkal1.iloc[0:N-2, 5].values * Psi1[:, 1]).reshape(-1, 1)\n",
        "    ys4 = (inputkal1.iloc[2:N, 6].values - inputkal1.iloc[1:N-1, 6].values * Psi4[:, 0] - inputkal1.iloc[0:N-2, 6].values * Psi4[:, 1]).reshape(-1, 1)\n",
        "    ys5 = (inputkal1.iloc[2:N, 7].values - inputkal1.iloc[1:N-1, 7].values * Psi5[:, 0] - inputkal1.iloc[0:N-2, 7].values * Psi5[:, 1]).reshape(-1, 1)\n",
        "\n",
        "# delta C*~\n",
        "    rrighta3 = (righta3[2:N].values - righta3[1:N-1].values * Psi1[:, 0] - righta3[0:N-2].values * Psi1[:, 1]).reshape(-1, 1)\n",
        "\n",
        "\n",
        "# posterior distribution of lamda variance\n",
        "    varlamda1 = 1 / (np.sum(rrighta3 * rrighta3.T) / (sig1 ** 2) + 1 / varlamda1)\n",
        "    varlamda2 = 1 / (np.sum(rrighta3 * rrighta3.T) / (sig2 ** 2) + 1 / varlamda2)\n",
        "    varlamda3 = 1 / (np.sum(rrighta3 * rrighta3.T) / (sig3 ** 2) + 1 / varlamda3)\n",
        "    varlamda4 = 1 / (np.sum(rrighta3 * rrighta3.T) / (sig4 ** 2) + 1 / varlamda4)\n",
        "    varlamda5 = 1 / (np.sum(rrighta3 * rrighta3.T) / (sig5 ** 2) + 1 / varlamda5)\n",
        "\n",
        "# posterior distribution of lamda mean\n",
        "\n",
        "    meanlamda1 = 1 / (np.sum(rrighta3 * rrighta3.T) / (sig1 ** 2) + 1 / varlamda1) * (meanlamda1 / varlamda1 + np.sum(rrighta3 * ys1.T) / (sig1 ** 2))\n",
        "    meanlamda2 = 1 / (np.sum(rrighta3 * rrighta3.T) / (sig2 ** 2) + 1 / varlamda2) * (meanlamda2 / varlamda2 + np.sum(rrighta3 * ys2.T) / (sig2 ** 2))\n",
        "    meanlamda3 = 1 / (np.sum(rrighta3 * rrighta3.T) / (sig3 ** 2) + 1 / varlamda3) * (meanlamda3 / varlamda3 + np.sum(rrighta3 * ys3.T) / (sig3 ** 2))\n",
        "    meanlamda4 = 1 / (np.sum(rrighta3 * rrighta3.T) / (sig4 ** 2) + 1 / varlamda4) * (meanlamda4 / varlamda4 + np.sum(rrighta3 * ys4.T) / (sig4 ** 2))\n",
        "    meanlamda5 = 1 / (np.sum(rrighta3 * rrighta3.T) / (sig5 ** 2) + 1 / varlamda5) * (meanlamda5 / varlamda5 + np.sum(rrighta3 * ys5.T) / (sig5 ** 2))\n",
        "\n",
        "#generate new lamda using new mean & new variance\n",
        "    lamda_1 = np.random.normal(meanlamda1, np.sqrt(varlamda1), (N, 1))\n",
        "    lamda_2 = np.random.normal(meanlamda2, np.sqrt(varlamda2), (N, 1))\n",
        "    lamda_3 = np.random.normal(meanlamda3, np.sqrt(varlamda3), (N, 1))\n",
        "    lamda_4 = np.random.normal(meanlamda4, np.sqrt(varlamda4), (N, 1))\n",
        "    lamda_5 = np.random.normal(meanlamda5, np.sqrt(varlamda5), (N, 1))\n",
        "\n",
        "# Section 2\n",
        "# generate new psi\n",
        "# Form Z and X as shown in the algorithm overview\n",
        "    Z1 = inputkal1.iloc[:, 3].values - inputkal1.iloc[:, 0].values * lamda_1.flatten()\n",
        "    Z2 = inputkal1.iloc[:, 4].values - inputkal1.iloc[:, 0].values * lamda_2.flatten()\n",
        "    Z3 = inputkal1.iloc[:, 5].values - inputkal1.iloc[:, 0].values * lamda_3.flatten()\n",
        "    Z4 = inputkal1.iloc[:, 6].values - inputkal1.iloc[:, 0].values * lamda_3.flatten()\n",
        "    Z5 = inputkal1.iloc[:, 7].values - inputkal1.iloc[:, 0].values * lamda_3.flatten()\n",
        "\n",
        "    X1 = np.column_stack((Z1[1:N - 1], Z1[:N - 2]))\n",
        "    X2 = np.column_stack((Z2[1:N - 1], Z2[:N - 2]))\n",
        "    X3 = np.column_stack((Z3[1:N - 1], Z3[:N - 2]))\n",
        "    X4 = np.column_stack((Z4[1:N - 1], Z4[:N - 2]))\n",
        "    X5 = np.column_stack((Z5[1:N - 1], Z5[:N - 2]))\n",
        "\n",
        "#save variance value of psi from last iteration for calculating mean of psi\n",
        "#as variance would get upgraded before calculating mean\n",
        "\n",
        "    fvarpsi1 = varpsi1\n",
        "    fvarpsi2 = varpsi2\n",
        "    fvarpsi3 = varpsi3\n",
        "    fvarpsi4 = varpsi4\n",
        "    fvarpsi5 = varpsi5\n",
        "\n",
        "# form varpsi^-1 for the variance matrix from last iteration\n",
        "# as a part of calculation for posterior distribution\n",
        "    ffvarpsi1 = np.linalg.pinv(varpsi1)\n",
        "    ffvarpsi2 = np.linalg.pinv(varpsi2)\n",
        "    ffvarpsi3 = np.linalg.pinv(varpsi3)\n",
        "    ffvarpsi4 = np.linalg.pinv(varpsi4)\n",
        "    ffvarpsi5 = np.linalg.pinv(varpsi5)\n",
        "# postrior variance of psi\n",
        "    varpsi1 = np.linalg.pinv(np.linalg.pinv(varpsi1) + X1.T @ X1 * sig1)\n",
        "    varpsi2 = np.linalg.pinv(np.linalg.pinv(varpsi2) + X2.T @ X2 * sig2)\n",
        "    varpsi3 = np.linalg.pinv(np.linalg.pinv(varpsi3) + X3.T @ X3 * sig3)\n",
        "    varpsi4 = np.linalg.pinv(np.linalg.pinv(varpsi4) + X4.T @ X4 * sig4)\n",
        "    varpsi5 = np.linalg.pinv(np.linalg.pinv(varpsi5) + X5.T @ X5 * sig4)\n",
        "# posterior mean of psi\n",
        "    meanpsi1 = np.dot(np.linalg.pinv(np.linalg.pinv(varpsi1) + X1.T @ X1 / (sig1 ** 2)) , (np.linalg.pinv(np.linalg.pinv(varpsi1))@ meanpsi1 + (X1.T @ Z1[2:N]).reshape(-1, 1) / (sig1 ** 2)))\n",
        "    meanpsi2 = np.dot(np.linalg.pinv(np.linalg.pinv(varpsi2) + X2.T @ X2 / (sig2 ** 2)) , (np.linalg.pinv(np.linalg.pinv(varpsi2))@ meanpsi2 + (X2.T @ Z2[2:N]).reshape(-1, 1) / (sig2 ** 2)))\n",
        "    meanpsi3 = np.dot(np.linalg.pinv(np.linalg.pinv(varpsi3) + X3.T @ X3 / (sig3 ** 2)) , (np.linalg.pinv(np.linalg.pinv(varpsi3))@ meanpsi3 + (X3.T @ Z3[2:N]).reshape(-1, 1) / (sig3 ** 2)))\n",
        "    meanpsi4 = np.dot(np.linalg.pinv(np.linalg.pinv(varpsi4) + X4.T @ X4 / (sig4 ** 2)) , (np.linalg.pinv(np.linalg.pinv(varpsi4))@ meanpsi4 + (X4.T @ Z4[2:N]).reshape(-1, 1) / (sig4 ** 2)))\n",
        "    meanpsi5 = np.dot(np.linalg.pinv(np.linalg.pinv(varpsi5) + X5.T @ X5 / (sig5 ** 2)) , (np.linalg.pinv(np.linalg.pinv(varpsi5))@ meanpsi5 + (X5.T @ Z5[2:N]).reshape(-1, 1) / (sig5 ** 2)))\n",
        "# sampling new psi with new mean & new variance for each psi_ij, i=1,2,3,4,5 j=1,2\n",
        "    psi_11 = np.random.normal(meanpsi1[0, :], np.sqrt(varpsi1[0, 0]), size=(N-2, 1))\n",
        "    psi_21 = np.random.normal(meanpsi2[0, :], np.sqrt(varpsi2[0, 0]), size=(N-2, 1))\n",
        "    psi_31 = np.random.normal(meanpsi3[0, :], np.sqrt(varpsi3[0, 0]), size=(N-2, 1))\n",
        "    psi_41 = np.random.normal(meanpsi4[0, :], np.sqrt(varpsi4[0, 0]), size=(N-2, 1))\n",
        "    psi_51 = np.random.normal(meanpsi5[0, :], np.sqrt(varpsi5[0, 0]), size=(N-2, 1))\n",
        "\n",
        "    psi_12 = np.random.normal(meanpsi1[1, :], np.sqrt(varpsi1[1, 1]), size=(N-2, 1))\n",
        "    psi_22 = np.random.normal(meanpsi2[1, :], np.sqrt(varpsi2[1, 1]), size=(N-2, 1))\n",
        "    psi_32 = np.random.normal(meanpsi3[1, :], np.sqrt(varpsi3[1, 1]), size=(N-2, 1))\n",
        "    psi_42 = np.random.normal(meanpsi4[1, :], np.sqrt(varpsi4[1, 1]), size=(N-2, 1))\n",
        "    psi_52 = np.random.normal(meanpsi5[1, :], np.sqrt(varpsi5[1, 1]), size=(N-2, 1))\n",
        "\n",
        "# Form new psi_ij (with size (N,1)) to psi_i as a matrix of size (N,2), first column is psi_i1, second column is psi_i2\n",
        "    Psi1 = np.column_stack((psi_21, psi_22))\n",
        "    Psi2 = np.column_stack((psi_21, psi_22))\n",
        "    Psi3 = np.column_stack((psi_31, psi_32))\n",
        "    Psi4 = np.column_stack((psi_41, psi_42))\n",
        "    Psi5 = np.column_stack((psi_51, psi_52))\n",
        "\n",
        "#Generating sigma_i, i=1,2,3,4,5\n",
        "    Xx1 = X1 * Psi1\n",
        "    Xx2 = X2 * Psi2\n",
        "    Xx3 = X3 * Psi3\n",
        "    Xx4 = X4 * Psi4\n",
        "    Xx5 = X5 * Psi5\n",
        "# sigma~IG(sig1a,sig1b), posterior sig1a=4+N/2 and it's fiexed\n",
        "# we only needs to calculate posterior sig1b\n",
        "    sig1b = 4 + 0.5 * np.dot(((Z1[2:N] - Xx1[:, 0] - Xx1[:, 1]).reshape(-1, 1)).T, (Z1[2:N] - Xx1[:, 0] - Xx1[:, 1]).reshape(-1, 1))\n",
        "    sig2b = 4 + 0.5 * np.dot(((Z2[2:N] - Xx2[:, 0] - Xx2[:, 1]).reshape(-1, 1)).T, (Z2[2:N] - Xx2[:, 0] - Xx2[:, 1]).reshape(-1, 1))\n",
        "    sig3b = 4 + 0.5 * np.dot(((Z3[2:N] - Xx3[:, 0] - Xx3[:, 1]).reshape(-1, 1)).T, (Z3[2:N] - Xx3[:, 0] - Xx3[:, 1]).reshape(-1, 1))\n",
        "    sig4b = 4 + 0.5 * np.dot(((Z4[2:N] - Xx4[:, 0] - Xx4[:, 1]).reshape(-1, 1)).T, (Z4[2:N] - Xx4[:, 0] - Xx4[:, 1]).reshape(-1, 1))\n",
        "    sig5b = 4 + 0.5 * np.dot(((Z5[2:N] - Xx5[:, 0] - Xx5[:, 1]).reshape(-1, 1)).T, (Z5[2:N] - Xx5[:, 0] - Xx5[:, 1]).reshape(-1, 1))\n",
        "\n",
        "# generate mew sigma_i with new sig_{i}b\n",
        "    sig1 = np.sqrt(1 / np.random.gamma(sig1a, 1 / sig1b))\n",
        "    sig2 = np.sqrt(1 / np.random.gamma(sig2a, 1 / sig2b))\n",
        "    sig3 = np.sqrt(1 / np.random.gamma(sig3a, 1 / sig3b))\n",
        "    sig4 = np.sqrt(1 / np.random.gamma(sig4a, 1 / sig4b))\n",
        "    sig5 = np.sqrt(1 / np.random.gamma(sig5a, 1 / sig5b))\n",
        "\n",
        "# Section 3\n",
        "# generate phi\n",
        "\n",
        "# Form G and Q as shown in the overview of section 3\n",
        "    G = inputkal1.iloc[4:N, 0] - mut[2:N - 2].T\n",
        "    Q[:, 0] = inputkal1.iloc[3:N-1, 0].values - np.reshape(mut[1:N-3], (-1, 1)).T\n",
        "    Q[:, 1] = inputkal1.iloc[2:N-2, 1].values - np.reshape(mut[0:N-4], (-1, 1)).T\n",
        "    Gg = G[0:N - 4]\n",
        "# save variance from last iteration\n",
        "    fvarphi = varphi\n",
        "# calculate posterior variance of phi\n",
        "    varphi = np.linalg.pinv(np.dot(Q.T, Q) + np.linalg.pinv(fvarphi))\n",
        "    aA1 = np.array([meanphi[0] / fvarphi[0,0], meanphi[1] / fvarphi[1,1]]).reshape((2, 1))\n",
        "    ffvarphi = np.array([fvarphi[0], fvarphi[1]])\n",
        "    fff = np.linalg.pinv(varphi)\n",
        "# there could be some 'inf' showing up at fff[0,1] and fff[1,0]\n",
        "# so we need to reform the matrix\n",
        "# the variance is still exactly same\n",
        "# so there won't be any impact on calculating posterior distribution\n",
        "\n",
        "    ffff = np.array([[fff[0, 0], 0], [0, fff[1, 1]]])\n",
        "\n",
        "# calculating posterior mean of phi\n",
        "    meanphi = np.linalg.inv(np.dot(Q.T, Q) + ffff) @ (np.dot(Q.T, Gg.T) + aA1)\n",
        "# sampling new phi\n",
        "    phi_1 = np.random.normal(meanphi[0], np.sqrt(varphi[0, 0]), size=(N - 2, 1))\n",
        "    phi_2 = np.random.normal(meanphi[1], np.sqrt(varphi[1, 1]), size=(N - 2, 1))\n",
        "\n",
        "# generating mu\n",
        "# form G* and Q* as shown in the overview of section 3\n",
        "    Gstar = inputkal1.iloc[4:N, 0].values.reshape(-1, 1) - phi_1[2:N - 2] * inputkal1.iloc[3:N - 1, 0].values.reshape(-1, 1) + phi_2[2:N - 2] * inputkal1.iloc[2:N - 2, 0].values.reshape(-1, 1)\n",
        "    mu0s = mu0[2:N - 2] * (np.ones((N - 4, 1)) - phi_1[2:N - 2] - phi_2[2:N - 2])\n",
        "    Qstar = np.zeros((N - 4, 2))\n",
        "    Qstar[:, 0] = (mu0s + np.random.normal(0, 1, size=(N - 4, 1))).flatten()\n",
        "    Qstar[:, 1] = (np.multiply(getattr(mut[2:N - 2], 'values', mut[2:N - 2]), getattr(St[2:N - 2], 'values', St[2:N - 2]))  - np.multiply(getattr(mut[2:N - 2], 'values', mut[2:N - 2]), getattr(phi_1[2:N - 2], 'values', phi_1[2:N - 2]) * getattr(St[1:N - 3], 'values', St[1:N - 3])) - np.multiply(getattr(mut[2:N - 2], 'values', mut[2:N - 2]), getattr(phi_2[2:N - 2], 'values', phi_2[2:N - 2]) * getattr(St[0:N - 4], 'values', St[0:N - 4])) + np.random.normal(0, 1, size=(N - 4, 1))).flatten()\n",
        "#save variance of mu from last iteration\n",
        "    fvarmu = varmu\n",
        "# generate posterior variance of mu\n",
        "    varmu = np.linalg.pinv(np.dot(Qstar.T, Qstar) + np.linalg.pinv(fvarmu))\n",
        "    ffvarmu = np.linalg.pinv(fvarmu) # inverse of former variance matrix from last iteration\n",
        "# same situation with phi,\n",
        "# there could be some 'inf' showing up at ffvarmu[0,1] and ffvarmu[1,0]\n",
        "# so we need to reform the matrix\n",
        "# the variance is still exactly same\n",
        "# there won't be any impact on calculating posterior distribution\n",
        "    fffvarmu = np.array([[ffvarmu[0, 0], 0], [0, ffvarmu[1, 1]]])\n",
        "# generate posterior mean value of mu\n",
        "    meanmu = np.linalg.inv(fffvarmu + np.dot(Qstar.T, Qstar)) @ (meanmu / np.array([[fvarmu[0, 0], fvarmu[1, 1]]]).T + np.dot(Qstar.T, Gstar))\n",
        "\n",
        "\n",
        "\n",
        "# same value of each iteration after first 2000 iterations\n",
        "    if i>burn:\n",
        "      mlamda1[i - burn] = meanlamda1\n",
        "      mlamda2[i - burn] = meanlamda2\n",
        "      mlamda3[i - burn] = meanlamda3\n",
        "      mlamda4[i - burn] = meanlamda4\n",
        "      mlamda5[i - burn] = meanlamda5\n",
        "      vlamda1[i - burn] = varlamda1\n",
        "      vlamda2[i - burn] = varlamda2\n",
        "      vlamda3[i - burn] = varlamda3\n",
        "      vlamda4[i - burn] = varlamda4\n",
        "      vlamda5[i - burn] = varlamda5\n",
        "      bsig1[i - burn] = sig1\n",
        "      bsig2[i - burn] = sig2\n",
        "      bsig3[i - burn] = sig3\n",
        "      bsig4[i - burn] = sig4\n",
        "      bsig5[i - burn] = sig5\n",
        "      mpsi11[i - burn] = meanpsi1[0, 0]\n",
        "      mpsi21[i - burn] = meanpsi2[0, 0]\n",
        "      mpsi31[i - burn] = meanpsi3[0, 0]\n",
        "      mpsi41[i - burn] = meanpsi4[0, 0]\n",
        "      mpsi51[i - burn] = meanpsi5[0, 0]\n",
        "      mpsi12[i - burn] = meanpsi1[1, 0]\n",
        "      mpsi22[i - burn] = meanpsi2[1, 0]\n",
        "      mpsi32[i - burn] = meanpsi3[1, 0]\n",
        "      mpsi42[i - burn] = meanpsi4[1, 0]\n",
        "      mpsi52[i - burn] = meanpsi5[1, 0]\n",
        "      vpsi11[i - burn] = varpsi1[0, 0]\n",
        "      vpsi21[i - burn] = varpsi2[0, 0]\n",
        "      vpsi31[i - burn] = varpsi3[0, 0]\n",
        "      vpsi41[i - burn] = varpsi4[0, 0]\n",
        "      vpsi51[i - burn] = varpsi5[0, 0]\n",
        "      vpsi12[i - burn] = varpsi1[1, 1]\n",
        "      vpsi22[i - burn] = varpsi2[1, 1]\n",
        "      vpsi32[i - burn] = varpsi3[1, 1]\n",
        "      vpsi42[i - burn] = varpsi4[1, 1]\n",
        "      vpsi52[i - burn] = varpsi5[1, 1]\n",
        "      mphi1[i - burn] = meanphi[0, 0]\n",
        "      mphi2[i - burn] = meanphi[1, 0]\n",
        "      vphi1[i - burn] = varphi[0, 0]\n",
        "      vphi2[i - burn] = varphi[1, 1]\n",
        "      mmu1[i - burn] = meanmu[0, 0]\n",
        "      mmu2[i - burn] = meanmu[1, 0]\n",
        "      vmu1[i - burn] = varmu[0, 0]\n",
        "      vmu2[i - burn] = varmu[1, 1]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "r2QWMLydk0wu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# after getting mean and variance from 8000 iterations, we take mean of 8000 iterations of mean value and variance value\n",
        "mmlamda1 = np.mean(mlamda1)\n",
        "mmlamda2 = np.mean(mlamda2)\n",
        "mmlamda3 = np.mean(mlamda3)\n",
        "mmlamda4 = np.mean(mlamda4)\n",
        "mmlamda5 = np.mean(mlamda5)\n",
        "vvlamda1 = np.mean(vlamda1)\n",
        "vvlamda2 = np.mean(vlamda2)\n",
        "vvlamda3 = np.mean(vlamda3)\n",
        "vvlamda4 = np.mean(vlamda4)\n",
        "vvlamda5 = np.mean(vlamda5)\n",
        "mbsig1 = np.mean(bsig1)\n",
        "mbsig2 = np.mean(bsig2)\n",
        "mbsig3 = np.mean(bsig3)\n",
        "mbsig4 = np.mean(bsig4)\n",
        "mbsig5 = np.mean(bsig5)\n",
        "mmpsi11 = np.mean(mpsi11)\n",
        "mmpsi21 = np.mean(mpsi21)\n",
        "mmpsi31 = np.mean(mpsi31)\n",
        "mmpsi41 = np.mean(mpsi41)\n",
        "mmpsi51 = np.mean(mpsi51)\n",
        "mmpsi12 = np.mean(mpsi12)\n",
        "mmpsi22 = np.mean(mpsi22)\n",
        "mmpsi32 = np.mean(mpsi32)\n",
        "mmpsi42 = np.mean(mpsi42)\n",
        "mmpsi52 = np.mean(mpsi52)\n",
        "vvpsi11 = np.mean(vpsi11)\n",
        "vvpsi21 = np.mean(vpsi21)\n",
        "vvpsi31 = np.mean(vpsi31)\n",
        "vvpsi41 = np.mean(vpsi41)\n",
        "vvpsi51 = np.mean(vpsi51)\n",
        "vvpsi12 = np.mean(vpsi12)\n",
        "vvpsi22 = np.mean(vpsi22)\n",
        "vvpsi32 = np.mean(vpsi32)\n",
        "vvpsi42 = np.mean(vpsi42)\n",
        "vvpsi52 = np.mean(vpsi52)\n",
        "mmphi1 = np.mean(mphi1)\n",
        "mmphi2 = np.mean(mphi2)\n",
        "vvphi1 = np.mean(vphi1)\n",
        "vvphi2 = np.mean(vphi2)\n",
        "mmmu1 = np.mean(mmu1)\n",
        "mmmu2 = np.mean(mmu2)\n",
        "vvmu1 = np.mean(vmu1)\n",
        "vvmu2 = np.mean(vmu2)\n",
        "sqrt_var_bsig1 = np.sqrt(np.var(bsig1))\n",
        "sqrt_var_bsig2 = np.sqrt(np.var(bsig2))\n",
        "sqrt_var_bsig3 = np.sqrt(np.var(bsig3))\n",
        "sqrt_var_bsig4 = np.sqrt(np.var(bsig4))\n",
        "sqrt_var_bsig5 = np.sqrt(np.var(bsig5))\n",
        "#sigma is slightly special as it follows inverse Gamma distribution\n",
        "#but Kim & Nelson (1998) still provides the mean and SD for sigma\n",
        "# so what we do here is to calculate mean and variance of 80000 sigma_i for i=1,2,3,4,5 from 8000 iterations\n",
        "mbsig1=np.mean(bsig1)\n",
        "mbsig2=np.mean(bsig2)\n",
        "mbsig3=np.mean(bsig3)\n",
        "mbsig4=np.mean(bsig4)\n",
        "mbsig5=np.mean(bsig5)\n",
        "\n",
        "#print all results\n",
        "print(\"mean of lamda1:\", mmlamda1)\n",
        "print(\"mean of lamda2:\", mmlamda2)\n",
        "print(\"mean of lamda3:\", mmlamda3)\n",
        "print(\"mean of lamda4:\", mmlamda4)\n",
        "print(\"mean of lamda5:\", mmlamda5)\n",
        "print(\"stanard deviation of lamda1:\", np.sqrt(vvlamda1))\n",
        "print(\"stanard deviation of lamda2:\", np.sqrt(vvlamda2))\n",
        "print(\"stanard deviation of lamda3:\", np.sqrt(vvlamda3))\n",
        "print(\"stanard deviation of lamda4:\", np.sqrt(vvlamda4))\n",
        "print(\"stanard deviation of lamda5:\", np.sqrt(vvlamda5))\n",
        "print(\"mean of psi11:\", mmpsi11)\n",
        "print(\"mean of psi21:\", mmpsi21)\n",
        "print(\"mean of psi31:\", mmpsi31)\n",
        "print(\"mean of psi41:\", mmpsi41)\n",
        "print(\"mean of psi51:\", mmpsi51)\n",
        "print(\"mean of psi12:\", mmpsi12)\n",
        "print(\"mean of psi22:\", mmpsi22)\n",
        "print(\"mean of psi32:\", mmpsi32)\n",
        "print(\"mean of psi42:\", mmpsi42)\n",
        "print(\"mean of psi52:\", mmpsi52)\n",
        "print(\"stanard deviation of psi11:\", np.sqrt(vvpsi11))\n",
        "print(\"stanard deviation of psi21:\", np.sqrt(vvpsi21))\n",
        "print(\"stanard deviation of psi31:\", np.sqrt(vvpsi31))\n",
        "print(\"stanard deviation of psi41:\", np.sqrt(vvpsi41))\n",
        "print(\"stanard deviation of psi51:\", np.sqrt(vvpsi51))\n",
        "print(\"stanard deviation of psi12:\", np.sqrt(vvpsi12))\n",
        "print(\"stanard deviation of psi22:\", np.sqrt(vvpsi22))\n",
        "print(\"stanard deviation of psi32:\", np.sqrt(vvpsi32))\n",
        "print(\"stanard deviation of psi42:\", np.sqrt(vvpsi42))\n",
        "print(\"stanard deviation of psi52:\", np.sqrt(vvpsi52))\n",
        "print(\"mean of phi1:\", mmphi1)\n",
        "print(\"mean of phi2:\", mmphi2)\n",
        "print(\"stanard deviation of phi1:\", np.sqrt(vvphi1))\n",
        "print(\"stanard deviation of phi2:\", np.sqrt(vvphi2))\n",
        "print(\"mean of mu1:\", mmmu1)\n",
        "print(\"mean of mu2:\", mmmu2)\n",
        "print(\"stanard deviation of mu1:\", np.sqrt(vvmu1))\n",
        "print(\"stanard deviation of mu2:\", np.sqrt(vvmu2))\n",
        "print(\"stanard deviation of sigma1:\", sqrt_var_bsig1)\n",
        "print(\"stanard deviation of sigma2:\", sqrt_var_bsig2)\n",
        "print(\"stanard deviation of sigma3:\", sqrt_var_bsig3)\n",
        "print(\"stanard deviation of sigma4:\", sqrt_var_bsig4)\n",
        "print(\"stanard deviation of sigma5:\", sqrt_var_bsig5)\n",
        "print(\"mean of sigma1:\", mbsig1)\n",
        "print(\"mean of sigma2:\", mbsig2)\n",
        "print(\"mean of sigma3:\", mbsig3)\n",
        "print(\"mean of sigma4:\", mbsig4)\n",
        "print(\"mean of sigma5:\", mbsig5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLR89Z3uND2T",
        "outputId": "df17b2e8-bb10-4d8e-dec0-3baa05d58d04"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean of lamda1: 9.95760865101711e-07\n",
            "mean of lamda2: -8.281413457797196e-05\n",
            "mean of lamda3: -0.014467960667868247\n",
            "mean of lamda4: -0.00013135563424465947\n",
            "mean of lamda5: -0.0007384407776915394\n",
            "stanard deviation of lamda1: 1.0437705927640504e-05\n",
            "stanard deviation of lamda2: 1.2995606340015074e-05\n",
            "stanard deviation of lamda3: 2.321061643080639e-05\n",
            "stanard deviation of lamda4: 1.2393825438831702e-05\n",
            "stanard deviation of lamda5: 1.1426824991890204e-05\n",
            "mean of psi11: 0.004218921559789076\n",
            "mean of psi21: 0.03099046836537819\n",
            "mean of psi31: 0.0032891786735667755\n",
            "mean of psi41: -0.0037651459113793554\n",
            "mean of psi51: 0.012976799020934503\n",
            "mean of psi12: 0.0018625936686717263\n",
            "mean of psi22: 0.004746312618659771\n",
            "mean of psi32: -0.0010252614836818285\n",
            "mean of psi42: -0.0018401089465949502\n",
            "mean of psi52: 0.004229692017536591\n",
            "stanard deviation of psi11: 0.5530388711413227\n",
            "stanard deviation of psi21: 0.04585155475890119\n",
            "stanard deviation of psi31: 0.004972164884994585\n",
            "stanard deviation of psi41: 0.019563629187897297\n",
            "stanard deviation of psi51: 0.02903599502978333\n",
            "stanard deviation of psi12: 0.5530836622714199\n",
            "stanard deviation of psi22: 0.045923563967964265\n",
            "stanard deviation of psi32: 0.00496668581479984\n",
            "stanard deviation of psi42: 0.019611031709374734\n",
            "stanard deviation of psi52: 0.02902046764127546\n",
            "mean of phi1: 0.0002864688779412151\n",
            "mean of phi2: 0.00025122420562579897\n",
            "stanard deviation of phi1: 0.0004288429894645395\n",
            "stanard deviation of phi2: 0.000427753990318085\n",
            "mean of mu1: 0.001043555745067229\n",
            "mean of mu2: 4.960224500534554e-06\n",
            "stanard deviation of mu1: 0.0005054629212827762\n",
            "stanard deviation of mu2: 0.0006263701528048656\n",
            "stanard deviation of sigma1: 0.0049840002352367595\n",
            "stanard deviation of sigma2: 0.006401119095334451\n",
            "stanard deviation of sigma3: 0.01103572488330428\n",
            "stanard deviation of sigma4: 0.005893459643093939\n",
            "stanard deviation of sigma5: 0.005369968844230067\n",
            "mean of sigma1: 0.13697117049019028\n",
            "mean of sigma2: 0.1751072061739043\n",
            "mean of sigma3: 0.30669197748161514\n",
            "mean of sigma4: 0.16210086085034933\n",
            "mean of sigma5: 0.14923605385737412\n"
          ]
        }
      ]
    }
  ]
}